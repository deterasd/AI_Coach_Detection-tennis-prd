import os
import pandas as pd
import json
import time
import re
import single_feedback.prompt as prompt
import single_feedback.model_config as model_config
from openai import OpenAI
from ai_config import ai_config

# --- è¨­å®š API åƒæ•¸èˆ‡è¼‰å…¥ Prompt èˆ‡æ¨¡å‹è¨­å®š ---
client = ai_config.get_client()
MODEL = ai_config.get_model_name()  # å¾ ai_config å‹•æ…‹ç²å–æ­£ç¢ºçš„æ¨¡å‹åç¨±
TEMPERATURE = model_config.TEMPERATURE
MAX_TOKENS = model_config.MAX_TOKENS
FREQUENCY_PENALTY = model_config.FREQUENCY_PENALTY
PRESENCE_PENALTY = model_config.PRESENCE_PENALTY
TOP_P = model_config.TOP_P

INSTRUCTIONS = prompt.INSTRUCTIONS
DATADESCIRBE = prompt.DATADESCIRBE

# ç°¡åŒ–ç³»çµ±æç¤ºè©ä»¥æå‡é€Ÿåº¦å’Œç©©å®šæ€§
system_content = """ä½ æ˜¯å°ˆæ¥­çš„ç¶²çƒæ•™ç·´ã€‚
è«‹æ ¹æ“š KNN åˆ†æçµæœï¼Œç”¨ 2 å¥è©±æè¿°éœ€è¦æ”¹é€²çš„å‹•ä½œéƒ¨ä½èˆ‡æ–¹å‘ã€‚
å›è¦†å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£å‹å–„ã€‚"""

def create_chat_completion(messages):
    """
    ä»¥çµ¦å®šçš„ messages å‘¼å« ChatCompletionï¼ˆæ”¯æ´ LM Studio æˆ– OpenAIï¼‰
    å›å‚³ç”¢ç”Ÿçš„ completion çµæœ
    """
    if client is None:
        print("âŒ AI å®¢æˆ¶ç«¯æœªåˆå§‹åŒ–")
        return None

    request_kwargs = dict(
        model=MODEL,
        messages=messages,
        temperature=TEMPERATURE,
        top_p=TOP_P,
        frequency_penalty=FREQUENCY_PENALTY,
        presence_penalty=PRESENCE_PENALTY,
    )

    # å„ªåŒ–åƒæ•¸è¨­å®šä»¥æå‡é€Ÿåº¦
    if ai_config.is_lm_studio():
        # LM Studio æœ¬åœ°æ¨¡å‹è¨­å®š - ä½¿ç”¨å„ªåŒ–åƒæ•¸
        print(f"ğŸ¤– ä½¿ç”¨ LM Studio æœ¬åœ°æ¨¡å‹: {MODEL}")
        request_kwargs["max_tokens"] = 100  # é™ä½è‡³ 100 ä»¥åŠ å¿«ç”Ÿæˆ
        request_kwargs["temperature"] = 0.5  # é™ä½è‡³ 0.5 æå‡é€Ÿåº¦
        request_kwargs["top_p"] = 0.9  # é™ä½è‡³ 0.9
    else:
        # OpenAI API è¨­å®š
        print(f"ğŸŒ ä½¿ç”¨ OpenAI API æ¨¡å‹: {MODEL}")
        model_lower = MODEL.lower()
        if any(prefix in model_lower for prefix in ("gpt-4o", "gpt-4.1", "gpt-5", "o1", "o3")):
            request_kwargs["max_completion_tokens"] = MAX_TOKENS
            if any(prefix in model_lower for prefix in ("gpt-5", "o1", "o3")):
                request_kwargs["temperature"] = 1
                request_kwargs.pop("frequency_penalty", None)
                request_kwargs.pop("presence_penalty", None)
                request_kwargs.pop("top_p", None)
        else:
            request_kwargs["max_tokens"] = MAX_TOKENS

    try:
        completion = client.chat.completions.create(**request_kwargs)
        return completion
    except Exception as e:
        print(f"âŒ API å‘¼å«å¤±æ•—: {e}")
        if ai_config.is_lm_studio():
            print("ğŸ’¡ è«‹ç¢ºèª LM Studio å·²å•Ÿå‹•ä¸”è¼‰å…¥æ¨¡å‹")
            print("ğŸ’¡ æˆ–è€…åŸ·è¡Œ ai_config.switch_to_openai() åˆ‡æ›åˆ° OpenAI API")
        else:
            print("ğŸ’¡ è«‹æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œ API é‡‘é‘°")
        return None

def generate_feedback(json_filepath, txt_filepath):
    """
    è®€å– JSON (é‹å‹•è»Œè·¡) èˆ‡ KNN çµæœ(txt)ï¼Œä¸¦ç¶œåˆå…©è€…è³‡è¨Šç”¢å‡º GPT å›é¥‹
    æœ€å¾Œå°‡çµæœè¼¸å‡ºç‚º _gpt_feedback.json æª”
    """
    # è®€å–é‹å‹•è»Œè·¡è³‡æ–™èˆ‡ KNN å›é¥‹
    my_motion = pd.read_json(json_filepath)
    knn_feedback = pd.read_csv(txt_filepath, header=None).iloc[0, 0]

    # åˆå§‹åŒ– messages åˆ—è¡¨ (LM Studio ä¸æ”¯æ´ system è§’è‰²ï¼Œå°‡å…§å®¹åˆä½µåˆ°ç¬¬ä¸€å€‹ user è¨Šæ¯)
    messages = []

    # å¦‚æœ knn_feedback ç‚ºç‰¹å®šæ­£å‘å›é¥‹è¨Šæ¯
    if knn_feedback == "é ­:æ²’å•é¡Œ!ã€è‚©è†€:æ²’å•é¡Œ!ã€æ‰‹ç¢—:æ²’å•é¡Œ!ã€æ‰‹è‚˜:æ²’å•é¡Œ!ã€è†è“‹:æ²’å•é¡Œ!ã€æ˜¯å¦æ“Šçƒ:æ˜¯ã€å…¶ä»–:ç„¡":
        knn_response = "æ²’æœ‰è§€å¯Ÿåˆ°é¡¯è‘—å•é¡Œï¼Œè«‹ç¹¼çºŒä¿æŒï¼"
        frame_response = "0-0"

        # å°‡ frame èˆ‡å»ºè­°å›é¥‹ä¸€èµ·é™„åŠ åˆ° messages ä¸­
        messages.append({"role": "assistant", "content": frame_response})
        messages.append({"role": "assistant", "content": knn_response})

    else:
        # ç¬¬ä¸€æ¬¡è®“ GPT æ ¹æ“š KNN Feedback ç”¢ç”Ÿä¸­æ–‡æ•˜è¿°
        messages.append({
            "role": "user",
            "content": system_content + f"""

                observe analysis results: {knn_feedback}, 
                Rephrase the analysis results of each body part in 1 sentence
            """
        })
        knn_completion = create_chat_completion(messages)
        knn_response = knn_completion.choices[0].message.content

        # æ ¹æ“š KNN å›é¥‹æ¨æ¸¬å•é¡Œå½±æ ¼ç¯„åœï¼ˆä¸éœ€è¦å®Œæ•´çš„è»Œè·¡æ•¸æ“šï¼‰
        total_frames = len(my_motion)
        messages.append({
            "role": "user",
            "content": f"""
                The feedback describes issues in a tennis swing motion with {total_frames} total frames.
                Based on the feedback: "{knn_response}", 
                speculate in which frame section the issue most likely occurs. 
                Please provide a broader frame range covering more frames (e.g., a range of at least 15 frames), 
                and You MUST respond with a numeric range only, in the format "number-number" (e.g., "13-24"), 
                containing only digits and a hyphen, with no additional text or formatting.
            """
        })
        frame_completion = create_chat_completion(messages)
        frame_response = frame_completion.choices[0].message.content

        # å°‡æ•¸å­—ç¯„åœèˆ‡ knn_response åŠ å…¥åˆ° messages (å¯ä»¥ç”¨æ–¼å¾ŒçºŒæª¢è¦–æˆ–é™¤éŒ¯)
        messages.append({"role": "assistant", "content": frame_response})
        messages.append({"role": "assistant", "content": knn_response})

    # è™•ç†æ›è¡Œç¬¦è™Ÿ
    frame_response = frame_response.replace("\n", "")
    knn_response = knn_response.replace("\n", "")

    # æ§‹é€  JSON æ ¼å¼å›å‚³çµæœ
    ai_feedback = {
        "problem_frame": frame_response,
        "suggestion": knn_response,
    }

    print(ai_feedback)

    # è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (ä»¥åŸæª”æ¡ˆåç¨± + "_gpt_feedback.json")
    output_filepath = json_filepath.replace('(3D_trajectory_smoothed)_only_swing.json', '_gpt_feedback.json')
    with open(output_filepath, "w", encoding="utf-8") as f:
        json.dump(ai_feedback, f, ensure_ascii=False, indent=2)

    return output_filepath

def generate_feedback_data_only(json_filepath, txt_filepath):
    """
    è®€å– JSON (é‹å‹•è»Œè·¡) èˆ‡ KNN çµæœ(txt)ï¼Œä¸¦ç¶œåˆå…©è€…è³‡è¨Šç”¢å‡º GPT å›é¥‹
    è¿”å›æ•¸æ“šè€Œä¸ä¿å­˜æª”æ¡ˆ
    å¦‚æœ API é…é¡ä¸è¶³æˆ–å…¶ä»–éŒ¯èª¤ï¼Œè¿”å›åŒ…å«éŒ¯èª¤è¨Šæ¯çš„å›æ‡‰
    """
    try:
        # è®€å–é‹å‹•è»Œè·¡è³‡æ–™ (ä½¿ç”¨ json.load ä»£æ›¿ pd.read_json)
        with open(json_filepath, 'r', encoding='utf-8') as f:
            trajectory_data = json.load(f)
        
        # è½‰æ›ç‚º DataFrame (å¦‚æœéœ€è¦çš„è©±)
        my_motion = pd.DataFrame(trajectory_data)
        
        # è®€å– KNN å›é¥‹
        knn_feedback = pd.read_csv(txt_filepath, header=None).iloc[0, 0]
    except Exception as e:
        print(f"âš ï¸ è®€å–è³‡æ–™å¤±æ•—: {e}")
        return {
            "problem_frame": "N/A",
            "suggestion": f"è³‡æ–™è®€å–å¤±æ•—: {str(e)}",
            "error": True
        }

    total_frames = len(my_motion)
    frame_response = "0-0"

    # ç‰¹æ®Šæƒ…æ³ï¼šå®Œå…¨ç„¡å•é¡Œçš„ KNN å›é¥‹ç›´æ¥å›å‚³å›ºå®šè¨Šæ¯
    if knn_feedback == "é ­:æ²’å•é¡Œ!ã€è‚©è†€:æ²’å•é¡Œ!ã€æ‰‹ç¢—:æ²’å•é¡Œ!ã€æ‰‹è‚˜:æ²’å•é¡Œ!ã€è†è“‹:æ²’å•é¡Œ!ã€æ˜¯å¦æ“Šçƒ:æ˜¯ã€å…¶ä»–:ç„¡":
        knn_response = "æ²’æœ‰è§€å¯Ÿåˆ°é¡¯è‘—å•é¡Œï¼Œè«‹ç¹¼çºŒä¿æŒï¼"
    else:
        knn_messages = [
            {
                "role": "user",
                "content": f"{system_content}\n\nKNN åˆ†æçµæœï¼š\n{knn_feedback}"
            }
        ]

        try:
            knn_completion = create_chat_completion(knn_messages)
            knn_response = knn_completion.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ GPT API å›æ‡‰éŒ¯èª¤: {error_msg}")

            if "429" in error_msg or "quota" in error_msg.lower() or "rate_limit" in error_msg.lower():
                print("âš ï¸ GPT API é…é¡ä¸è¶³ï¼Œä½¿ç”¨ KNN åˆ†æçµæœä½œç‚ºæ›¿ä»£")
                return {
                    "problem_frame": "0-0",
                    "suggestion": f"KNNåˆ†æçµæœ: {knn_feedback}\n(è¨»: GPTé…é¡ä¸è¶³ï¼Œåƒ…é¡¯ç¤ºKNNåˆ†æ)",
                    "error": True,
                    "error_type": "quota_exceeded"
                }
            else:
                print("âš ï¸ GPT API ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤ï¼Œä½¿ç”¨ KNN åˆ†æçµæœä½œç‚ºæ›¿ä»£")
                return {
                    "problem_frame": "0-0",
                    "suggestion": f"KNNåˆ†æçµæœ: {knn_feedback}\n(è¨»: GPTæš«æ™‚ç„¡æ³•ä½¿ç”¨ - {error_msg})",
                    "error": True,
                    "error_type": "api_error"
                }

        # å–å¾—å‹•ä½œå•é¡Œæ‰€åœ¨çš„å½±æ ¼ç¯„åœï¼ˆç°¡åŒ–ï¼šå›ºå®šå›å‚³é è¨­å€¼ï¼‰
        # ç§»é™¤è€—æ™‚çš„å½±æ ¼æ¨æ¸¬æ­¥é©Ÿä»¥æå‡æ•´é«”é€Ÿåº¦
        frame_response = "0-0"

    # æ­£è¦åŒ–è¼¸å‡ºå…§å®¹
    knn_response = (knn_response or "").replace("\n", " ").strip()

    frame_response = (frame_response or "0-0").strip()
    match = re.search(r"(\d+)\s*-\s*(\d+)", frame_response)
    if match:
        start_frame = int(match.group(1))
        end_frame = int(match.group(2))
        if end_frame < start_frame:
            start_frame, end_frame = end_frame, start_frame
        if total_frames > 0:
            start_frame = max(0, min(start_frame, total_frames - 1))
            end_frame = max(0, min(end_frame, total_frames - 1))
        frame_response = f"{start_frame}-{end_frame}"
    else:
        frame_response = "0-0"

    ai_feedback = {
        "problem_frame": frame_response,
        "suggestion": knn_response or f"KNNåˆ†æçµæœ: {knn_feedback}",
    }

    return ai_feedback


if __name__ == "__main__":
    json_path = "å˜‰æ´‹__3(3D_trajectory_smoothed).json"
    txt_path = "å˜‰æ´‹__3_knn_feedback.txt"

    # é–‹å§‹è¨ˆæ™‚
    start_time = time.time()

    # ç”¢ç”Ÿä¸¦è¼¸å‡ºå›é¥‹
    output_filepath = generate_feedback(json_path, txt_path)

    # çµæŸè¨ˆæ™‚
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("AI Feedback:")
    print(f"Processing time: {elapsed_time:.2f} seconds")