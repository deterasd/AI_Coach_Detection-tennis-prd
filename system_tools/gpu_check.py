#!/usr/bin/env python3
"""
GPU æª¢æ¸¬å·¥å…·
æª¢æŸ¥ç³»çµ±GPUç‹€æ…‹å’ŒCUDAå¯ç”¨æ€§
"""

import subprocess
import sys
from pathlib import Path

def check_nvidia_gpu():
    """æª¢æŸ¥NVIDIA GPU"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… æª¢æ¸¬åˆ° NVIDIA GPU:")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'RTX' in line or 'GTX' in line or 'Tesla' in line:
                    print(f"   {line.strip()}")
            return True
        else:
            print("âŒ nvidia-smi åŸ·è¡Œå¤±æ•—")
            return False
    except:
        print("âŒ æœªå®‰è£ NVIDIA é©…å‹•ç¨‹å¼æˆ– nvidia-smi")
        return False

def check_cuda():
    """æª¢æŸ¥CUDAç‰ˆæœ¬"""
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            for line in result.stdout.split('\n'):
                if 'release' in line:
                    print(f"âœ… CUDA ç‰ˆæœ¬: {line.strip()}")
                    return True
        return False
    except:
        print("âŒ CUDA æœªå®‰è£æˆ–ä¸åœ¨ç³»çµ±è·¯å¾‘ä¸­")
        return False

def check_opencv_gpu():
    """æª¢æŸ¥OpenCV GPUæ”¯æ´"""
    try:
        import cv2
        print(f"âœ… OpenCV ç‰ˆæœ¬: {cv2.__version__}")
        
        # æª¢æŸ¥CUDAæ”¯æ´
        if cv2.cuda.getCudaEnabledDeviceCount() > 0:
            print(f"âœ… OpenCV æ”¯æ´ CUDAï¼Œå¯ç”¨GPUæ•¸é‡: {cv2.cuda.getCudaEnabledDeviceCount()}")
            return True
        else:
            print("âŒ OpenCV ä¸æ”¯æ´ CUDA æˆ–æœªæª¢æ¸¬åˆ° GPU")
            return False
    except ImportError:
        print("âŒ OpenCV æœªå®‰è£")
        return False
    except:
        print("âŒ OpenCV CUDA æª¢æŸ¥å¤±æ•—")
        return False

def check_ffmpeg_gpu():
    """æª¢æŸ¥FFmpeg GPUæ”¯æ´"""
    ffmpeg_paths = ['ffmpeg', str(Path('tools/ffmpeg.exe').absolute())]
    
    for ffmpeg_cmd in ffmpeg_paths:
        try:
            result = subprocess.run([ffmpeg_cmd, '-encoders'], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print(f"âœ… æ‰¾åˆ° FFmpeg: {ffmpeg_cmd}")
                
                # æª¢æŸ¥NVIDIAç·¨ç¢¼å™¨
                encoders = result.stdout
                nvidia_encoders = []
                
                if 'h264_nvenc' in encoders:
                    nvidia_encoders.append('h264_nvenc')
                if 'hevc_nvenc' in encoders:
                    nvidia_encoders.append('hevc_nvenc')
                if 'av1_nvenc' in encoders:
                    nvidia_encoders.append('av1_nvenc')
                
                if nvidia_encoders:
                    print(f"âœ… FFmpeg æ”¯æ´ NVIDIA ç·¨ç¢¼å™¨: {', '.join(nvidia_encoders)}")
                    return True
                else:
                    print("âŒ FFmpeg ä¸æ”¯æ´ NVIDIA ç·¨ç¢¼å™¨")
                    return False
        except:
            continue
    
    print("âŒ æœªæ‰¾åˆ° FFmpeg")
    return False

def check_python_gpu_libs():
    """æª¢æŸ¥Python GPUç›¸é—œå‡½å¼åº«"""
    gpu_libs = []
    
    # æª¢æŸ¥PyTorch
    try:
        import torch
        if torch.cuda.is_available():
            gpu_libs.append(f"PyTorch (CUDA {torch.version.cuda})")
        else:
            print("âŒ PyTorch ä¸æ”¯æ´ CUDA")
    except ImportError:
        pass
    
    # æª¢æŸ¥TensorFlow
    try:
        import tensorflow as tf
        if tf.config.list_physical_devices('GPU'):
            gpu_libs.append("TensorFlow")
        else:
            print("âŒ TensorFlow ä¸æ”¯æ´ GPU")
    except (ImportError, ModuleNotFoundError):
        pass
    
    if gpu_libs:
        print(f"âœ… GPU ç›¸é—œå‡½å¼åº«: {', '.join(gpu_libs)}")
        return True
    else:
        print("â“ æœªå®‰è£ PyTorch æˆ– TensorFlow")
        return False

def main():
    print("=== GPU å’Œ CUDA ç’°å¢ƒæª¢æ¸¬ ===\n")
    
    print("1. æª¢æŸ¥ NVIDIA GPU:")
    gpu_available = check_nvidia_gpu()
    print()
    
    print("2. æª¢æŸ¥ CUDA:")
    cuda_available = check_cuda()
    print()
    
    print("3. æª¢æŸ¥ OpenCV GPU æ”¯æ´:")
    opencv_gpu = check_opencv_gpu()
    print()
    
    print("4. æª¢æŸ¥ FFmpeg GPU æ”¯æ´:")
    ffmpeg_gpu = check_ffmpeg_gpu()
    print()
    
    print("5. æª¢æŸ¥ Python GPU å‡½å¼åº«:")
    python_gpu = check_python_gpu_libs()
    print()
    
    print("=== ç¸½çµ ===")
    if gpu_available:
        print("âœ… GPU ç¡¬é«”: å¯ç”¨")
    else:
        print("âŒ GPU ç¡¬é«”: ä¸å¯ç”¨")
    
    if cuda_available:
        print("âœ… CUDA ç’°å¢ƒ: å¯ç”¨")
    else:
        print("âŒ CUDA ç’°å¢ƒ: ä¸å¯ç”¨")
    
    if ffmpeg_gpu:
        print("âœ… FFmpeg GPU åŠ é€Ÿ: å¯ç”¨")
    else:
        print("âŒ FFmpeg GPU åŠ é€Ÿ: ä¸å¯ç”¨")
    
    if opencv_gpu:
        print("âœ… OpenCV GPU åŠ é€Ÿ: å¯ç”¨")
    else:
        print("âŒ OpenCV GPU åŠ é€Ÿ: ä¸å¯ç”¨")
    
    # çµ¦å‡ºå»ºè­°
    print("\n=== å»ºè­° ===")
    if not gpu_available:
        print("ğŸ’¡ è«‹ç¢ºèª NVIDIA é©…å‹•ç¨‹å¼å·²æ­£ç¢ºå®‰è£")
    elif not cuda_available:
        print("ğŸ’¡ è«‹å®‰è£ CUDA Toolkit")
    elif not ffmpeg_gpu:
        print("ğŸ’¡ è«‹ä½¿ç”¨æ”¯æ´ GPU çš„ FFmpeg ç‰ˆæœ¬")
    else:
        print("ğŸ‰ æ‰€æœ‰ GPU åŠ é€Ÿæ¢ä»¶éƒ½å·²æ»¿è¶³ï¼")

if __name__ == "__main__":
    main()