"""
å½±ç‰‡è‡ªå‹•åˆ†å‰²å‘½ä»¤è¡Œæ¸¬è©¦å·¥å…·
ç°¡åŒ–ç‰ˆæœ¬ï¼Œç”¨æ–¼å¿«é€Ÿæ¸¬è©¦åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
python video_segment_test_cli.py input_video.mp4

æˆ–è€…è¨­å®šåƒæ•¸:
python video_segment_test_cli.py input_video.mp4 --confidence 0.6 --duration 5 --min-interval 3
"""

import cv2
import os
import sys
import json
import argparse
import numpy as np
from pathlib import Path
from datetime import datetime

try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯ï¼Œé¿å…GUIå•é¡Œ
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("è­¦å‘Š: ç„¡æ³•å°å…¥ matplotlibï¼Œå°‡ç„¡æ³•ç”Ÿæˆåœ–è¡¨")

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("è­¦å‘Š: ç„¡æ³•å°å…¥ YOLOï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")

def create_analysis_visualization(detection_results, ball_entry_times, video_path, confidence_threshold, segment_duration=-2):
    """
    å‰µå»ºåˆ†æçµæœçš„å¯è¦–åŒ–åœ–è¡¨ä¸¦ä¿å­˜ç‚ºåœ–ç‰‡
    
    åƒæ•¸:
    - detection_results: åµæ¸¬çµæœåˆ—è¡¨
    - ball_entry_times: çƒé€²å…¥æ™‚é–“é»
    - video_path: å½±ç‰‡è·¯å¾‘ 
    - confidence_threshold: ä¿¡å¿ƒåº¦é–¾å€¼
    - segment_duration: ç‰‡æ®µæ™‚é•·ï¼ˆè² æ•¸è¡¨ç¤ºå¾€å‰åç§»ï¼‰
    """
    if not MATPLOTLIB_AVAILABLE or not detection_results:
        print("âš ï¸ matplotlib ä¸å¯ç”¨æˆ–æ²’æœ‰åµæ¸¬çµæœï¼Œè·³éå¯è¦–åŒ–")
        return None
        
    try:
        # å‰µå»ºåœ–è¡¨ - 3å€‹å­åœ–
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 12))
        
        # åœ–1: åµæ¸¬ä¿¡å¿ƒåº¦æ™‚é–“åºåˆ—
        times = [r['time'] for r in detection_results]
        confidences = [r['confidence'] for r in detection_results]
        
        ax1.plot(times, confidences, 'b-', alpha=0.7, linewidth=1)
        ax1.axhline(y=confidence_threshold, color='r', linestyle='--', 
                   label=f'ä¿¡å¿ƒåº¦é–¾å€¼ ({confidence_threshold})')
        
        # æ¨™è¨˜çƒé€²å…¥æ™‚é–“é»
        for entry_time in ball_entry_times:
            ax1.axvline(x=entry_time, color='g', linestyle='-', alpha=0.8, linewidth=2)
            ax1.text(entry_time, ax1.get_ylim()[1]*0.9, f'{entry_time:.1f}s', 
                    rotation=90, ha='right', va='top')
        
        ax1.set_xlabel('æ™‚é–“ (ç§’)')
        ax1.set_ylabel('åµæ¸¬ä¿¡å¿ƒåº¦')
        ax1.set_title('ç¶²çƒåµæ¸¬ä¿¡å¿ƒåº¦ vs æ™‚é–“')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åœ–2: åµæ¸¬ç‹€æ…‹èˆ‡é‚Šç·£ä½ç½®
        detected_states = [1 if r['detected'] else 0 for r in detection_results]
        edge_states = [0.5 if r.get('in_edge', False) else 0 for r in detection_results]
        
        ax2.fill_between(times, detected_states, alpha=0.6, color='orange', label='åµæ¸¬åˆ°çƒ')
        ax2.fill_between(times, edge_states, alpha=0.4, color='purple', label='çƒåœ¨é‚Šç·£')
        
        # æ¨™è¨˜é è¨ˆåˆ†å‰²å€é–“
        for i, entry_time in enumerate(ball_entry_times):
            start_time = max(0, entry_time + segment_duration)
            end_time = start_time + abs(segment_duration) + 2  # å‡è¨­ç‰‡æ®µé•·åº¦
            ax2.axvspan(start_time, end_time, alpha=0.3, color='red', 
                       label='åˆ†å‰²å€é–“' if i == 0 else '')
            ax2.text(start_time + (end_time - start_time)/2, 0.75, 
                    f'ç‰‡æ®µ{i+1}', ha='center', va='center', 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        ax2.set_xlabel('æ™‚é–“ (ç§’)')
        ax2.set_ylabel('åµæ¸¬ç‹€æ…‹')
        ax2.set_title('ç¶²çƒåµæ¸¬ç‹€æ…‹èˆ‡åˆ†å‰²å€é–“ (ç´«è‰²=é‚Šç·£ä½ç½®)')
        ax2.set_ylim(-0.1, 1.1)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # åœ–3: çƒçš„ä½ç½®è»Œè·¡ (å¦‚æœæœ‰ä½ç½®è³‡è¨Š)
        x_positions = []
        y_positions = []
        valid_times = []
        
        for r in detection_results:
            if r['detected'] and r.get('position'):
                x, y = r['position']
                x_positions.append(x)
                y_positions.append(y)
                valid_times.append(r['time'])
        
        if x_positions:
            # å‰µå»ºé¡è‰²æ˜ å°„è¡¨ç¤ºæ™‚é–“
            scatter = ax3.scatter(x_positions, y_positions, c=valid_times, 
                                cmap='viridis', alpha=0.6, s=20)
            
            # æ¨™è¨˜çƒé€²å…¥é»
            for entry_time in ball_entry_times:
                # æ‰¾åˆ°æœ€æ¥è¿‘é€²å…¥æ™‚é–“çš„ä½ç½®
                closest_idx = min(range(len(valid_times)), 
                                 key=lambda i: abs(valid_times[i] - entry_time))
                if abs(valid_times[closest_idx] - entry_time) < 0.5:  # 0.5ç§’å…§
                    ax3.scatter(x_positions[closest_idx], y_positions[closest_idx], 
                              color='red', s=100, marker='*', 
                              label='çƒé€²å…¥é»' if entry_time == ball_entry_times[0] else '')
            
            ax3.set_xlabel('X ä½ç½® (åƒç´ )')
            ax3.set_ylabel('Y ä½ç½® (åƒç´ )')
            ax3.set_title('çƒçš„ä½ç½®è»Œè·¡ (é¡è‰²è¡¨ç¤ºæ™‚é–“ï¼Œç´…æ˜Ÿè¡¨ç¤ºé€²å…¥é»)')
            ax3.invert_yaxis()  # åè½‰Yè»¸ï¼Œå› ç‚ºå½±åƒåº§æ¨™ç³»Yè»¸å‘ä¸‹
            ax3.grid(True, alpha=0.3)
            ax3.legend()
            
            # æ·»åŠ è‰²æ¢
            cbar = plt.colorbar(scatter, ax=ax3)
            cbar.set_label('æ™‚é–“ (ç§’)')
        else:
            ax3.text(0.5, 0.5, 'ç„¡ä½ç½®è³‡è¨Šå¯é¡¯ç¤º', ha='center', va='center', 
                    transform=ax3.transAxes, fontsize=16)
            ax3.set_title('çƒçš„ä½ç½®è»Œè·¡')
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        video_name = Path(video_path).stem
        output_path = Path(video_path).parent / f"{video_name}_analysis.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()  # é—œé–‰åœ–è¡¨é‡‹æ”¾è¨˜æ†¶é«”
        
        print(f"ğŸ“Š åˆ†æåœ–è¡¨å·²ä¿å­˜: {output_path}")
        return str(output_path)
        
    except Exception as e:
        print(f"âŒ å»ºç«‹å¯è¦–åŒ–å¤±æ•—: {str(e)}")
        return None

def generate_simulation_data(video_path, confidence_threshold=0.5, min_interval=2.0):
    """
    ç”Ÿæˆæ¨¡æ“¬çš„çƒæª¢æ¸¬æ•¸æ“šï¼Œç”¨æ–¼æ¸¬è©¦åŠŸèƒ½
    """
    import random
    import math
    
    # æ¨¡æ“¬å½±ç‰‡åƒæ•¸
    duration = 30.0  # 30ç§’å½±ç‰‡
    fps = 30
    total_frames = int(duration * fps)
    
    detection_results = []
    ball_entry_times = []
    
    # æ¨¡æ“¬3å€‹çƒé€²å…¥çš„æ™‚é–“é»
    entry_scenarios = [5.2, 12.8, 21.5]  # ç§’
    
    print(f"ğŸ­ ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š: {duration}ç§’å½±ç‰‡, {total_frames}å¹€")
    
    for frame in range(total_frames):
        current_time = frame / fps
        
        # æ¨¡æ“¬æª¢æ¸¬é‚è¼¯
        detected = False
        confidence = 0.0
        position = None
        in_edge = False
        
        # æª¢æŸ¥æ˜¯å¦æ¥è¿‘çƒé€²å…¥æ™‚é–“é»
        for entry_time in entry_scenarios:
            time_diff = abs(current_time - entry_time)
            
            if time_diff < 2.0:  # çƒé€²å…¥å‰å¾Œ2ç§’å…§æœ‰æª¢æ¸¬
                # è·é›¢çƒé€²å…¥æ™‚é–“è¶Šè¿‘ï¼Œæª¢æ¸¬æ©Ÿç‡è¶Šé«˜
                detection_prob = 1.0 - (time_diff / 2.0)
                
                if random.random() < detection_prob:
                    detected = True
                    confidence = random.uniform(0.3, 0.9)
                    
                    # æ¨¡æ“¬ä½ç½® - åœ¨é‚Šç·£é€²å…¥æ™‚é–“é»é™„è¿‘ï¼Œçƒåœ¨é‚Šç·£
                    if time_diff < 0.5:  # é€²å…¥ç¬é–“åœ¨é‚Šç·£
                        position = (random.uniform(50, 150), random.uniform(100, 300))  # å·¦é‚Šç·£
                        in_edge = True
                    else:  # å…¶ä»–æ™‚é–“åœ¨ä¸­å¤®
                        position = (random.uniform(300, 500), random.uniform(200, 400))
                        in_edge = False
        
        # æ·»åŠ ä¸€äº›éš¨æ©Ÿå™ªéŸ³æª¢æ¸¬
        if not detected and random.random() < 0.05:  # 5%æ©Ÿç‡èª¤æª¢
            detected = True
            confidence = random.uniform(0.2, 0.4)
            position = (random.uniform(100, 600), random.uniform(100, 400))
            in_edge = random.choice([True, False])
        
        detection_results.append({
            'frame': frame,
            'time': current_time,
            'detected': detected,
            'confidence': confidence,
            'position': position,
            'in_edge': in_edge
        })
    
    # åŸºæ–¼æª¢æ¸¬çµæœæ‰¾å‡ºçƒé€²å…¥æ™‚é–“é»
    previous_detected = False
    
    for result in detection_results:
        current_detected = result['detected'] and result['confidence'] >= confidence_threshold
        
        if current_detected and not previous_detected and result['in_edge']:
            current_time = result['time']
            # æª¢æŸ¥æœ€å°é–“éš”
            if not ball_entry_times or (current_time - ball_entry_times[-1]) >= min_interval:
                ball_entry_times.append(current_time)
        
        previous_detected = current_detected
    
    print(f"ğŸ¯ æ¨¡æ“¬æ‰¾åˆ° {len(ball_entry_times)} å€‹çƒé€²å…¥æ™‚é–“é»:")
    for i, time_point in enumerate(ball_entry_times):
        print(f"   {i+1}. {time_point:.2f}ç§’ (æ¨¡æ“¬)")
    
    return ball_entry_times, detection_results

def detect_ball_entry_points(video_path, model=None, confidence_threshold=0.5, min_interval=2.0):
    """
    åµæ¸¬ç¶²çƒé€²å…¥ç•«é¢çš„æ™‚é–“é»
    
    åƒæ•¸:
    - video_path: å½±ç‰‡è·¯å¾‘
    - model: YOLOæ¨¡å‹ (å¦‚æœç‚ºNoneå‰‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼)
    - confidence_threshold: ä¿¡å¿ƒåº¦é–¾å€¼
    - min_interval: æœ€å°é–“éš”æ™‚é–“(ç§’)
    
    è¿”å›:
    - ball_entry_times: çƒé€²å…¥æ™‚é–“é»åˆ—è¡¨
    - detection_results: è©³ç´°åµæ¸¬çµæœ
    """
    print(f"ğŸ¬ é–‹å§‹åˆ†æå½±ç‰‡: {Path(video_path).name}")
    
    # å¦‚æœæ²’æœ‰æ¨¡å‹ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
    if model is None:
        print("ğŸ­ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ç”Ÿæˆæ¸¬è©¦æ•¸æ“š")
        return generate_simulation_data(video_path, confidence_threshold, min_interval)
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    
    print(f"ğŸ“Š å½±ç‰‡è³‡è¨Š: {total_frames} å½±æ ¼, {fps:.2f} FPS, {duration:.2f} ç§’")
    
    ball_entry_times = []
    detection_results = []
    
    previous_ball_detected = False
    previous_ball_position = None
    last_entry_time = -min_interval
    frame_count = 0
    
    # ç²å–ç•«é¢å°ºå¯¸è³‡è¨Š
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # å®šç¾©ç•«é¢é‚Šç·£å€åŸŸ
    edge_threshold = 0.15  # é‚Šç·£å€åŸŸä½”ç•«é¢çš„æ¯”ä¾‹
    left_edge = frame_width * edge_threshold
    right_edge = frame_width * (1 - edge_threshold)
    top_edge = frame_height * edge_threshold
    bottom_edge = frame_height * (1 - edge_threshold)
    
    print(f"ï¿½ ç•«é¢å°ºå¯¸: {frame_width}x{frame_height}")
    print(f"ğŸ¯ é‚Šç·£åµæ¸¬å€åŸŸ: å·¦({left_edge:.0f}), å³({right_edge:.0f}), ä¸Š({top_edge:.0f}), ä¸‹({bottom_edge:.0f})")
    
    print("ï¿½ğŸ” æ­£åœ¨åˆ†æå½±æ ¼...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        current_time = frame_count / fps
        
        # åµæ¸¬ç¶²çƒå’Œä½ç½®
        current_ball_detected = False
        max_confidence = 0
        ball_position = None
        ball_in_edge = False
        
        if model and YOLO_AVAILABLE:
            # ä½¿ç”¨çœŸå¯¦çš„YOLOæ¨¡å‹
            results = model(frame, verbose=False)
            
            if len(results[0].boxes) > 0:
                best_box = None
                best_confidence = 0
                
                for box in results[0].boxes:
                    confidence = float(box.conf[0])
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_box = box
                
                if best_confidence > confidence_threshold:
                    current_ball_detected = True
                    max_confidence = best_confidence
                    
                    # å–å¾—çƒçš„ä½ç½®
                    x1, y1, x2, y2 = best_box.xyxy[0].cpu().numpy()
                    ball_center_x = (x1 + x2) / 2
                    ball_center_y = (y1 + y2) / 2
                    ball_position = (ball_center_x, ball_center_y)
                    
                    # æª¢æŸ¥æ˜¯å¦åœ¨é‚Šç·£
                    ball_in_edge = (ball_center_x < left_edge or ball_center_x > right_edge or
                                   ball_center_y < top_edge or ball_center_y > bottom_edge)
        else:
            # æ¨¡æ“¬æ¨¡å¼ï¼šåŸºæ–¼å½±åƒè®ŠåŒ–åµæ¸¬ç§»å‹•ç‰©é«”
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ç°¡å–®çš„é‹å‹•åµæ¸¬æ¨¡æ“¬
            if frame_count > 0:
                diff = cv2.absdiff(gray, prev_gray)
                motion_pixels = np.sum(diff > 30)
                motion_ratio = motion_pixels / (frame.shape[0] * frame.shape[1])
                
                # æ¨¡æ“¬ä¿¡å¿ƒåº¦å’Œåµæ¸¬çµæœ
                max_confidence = min(motion_ratio * 10, 1.0)
                current_ball_detected = motion_ratio > 0.01  # æ¨¡æ“¬é–¾å€¼
                
                if current_ball_detected:
                    # æ¨¡æ“¬çƒçš„ä½ç½®ï¼ˆåœ¨æœ‰é‹å‹•çš„å€åŸŸä¸­å¿ƒï¼‰
                    y_indices, x_indices = np.where(diff > 30)
                    if len(x_indices) > 0:
                        ball_center_x = np.mean(x_indices)
                        ball_center_y = np.mean(y_indices)
                        ball_position = (ball_center_x, ball_center_y)
                        ball_in_edge = (ball_center_x < left_edge or ball_center_x > right_edge or
                                       ball_center_y < top_edge or ball_center_y > bottom_edge)
            else:
                max_confidence = 0
                current_ball_detected = False
                
            if 'prev_gray' not in locals():
                prev_gray = gray.copy()
            else:
                prev_gray = gray.copy()
        
        # è¨˜éŒ„åµæ¸¬çµæœ
        detection_results.append({
            'frame': frame_count,
            'time': current_time,
            'detected': current_ball_detected,
            'confidence': max_confidence,
            'position': ball_position,
            'in_edge': ball_in_edge
        })
        
        # åˆ¤æ–·çƒé€²å…¥ç•«é¢çš„é‚è¼¯
        is_ball_entry = False
        entry_reason = ""
        
        if current_ball_detected and ball_position:
            ball_center_x, ball_center_y = ball_position
            
            if current_ball_detected and not previous_ball_detected:
                # æƒ…æ³1: çƒå¾ç„¡åˆ°æœ‰å‡ºç¾
                if ball_in_edge:
                    # çƒå‡ºç¾åœ¨é‚Šç·£ = çƒå¾ç•«é¢å¤–é€²å…¥
                    is_ball_entry = True
                    entry_reason = f"é‚Šç·£é€²å…¥ (ä½ç½®: {ball_center_x:.0f}, {ball_center_y:.0f})"
                else:
                    # çƒå‡ºç¾åœ¨ä¸­å¤® = å¯èƒ½æ˜¯æ“Šçƒç¬é–“ï¼Œä¸ç®—é€²å…¥
                    entry_reason = f"ä¸­å¤®å‡ºç¾ (ä½ç½®: {ball_center_x:.0f}, {ball_center_y:.0f}) - å¿½ç•¥"
            
            elif current_ball_detected and previous_ball_detected and previous_ball_position:
                # æƒ…æ³2: çƒæŒçºŒå­˜åœ¨ï¼Œæª¢æŸ¥æ˜¯å¦å¾é‚Šç·£ç§»å‘ä¸­å¤®
                prev_x, prev_y = previous_ball_position
                curr_x, curr_y = ball_position
                
                # æª¢æŸ¥çƒæ˜¯å¦å¾é‚Šç·£ç§»åˆ°ä¸­å¤® (ç§»å‹•æ–¹å‘åˆ†æ)
                prev_in_edge = (prev_x < left_edge or prev_x > right_edge or
                               prev_y < top_edge or prev_y > bottom_edge)
                
                if prev_in_edge and not ball_in_edge:
                    # çƒå¾é‚Šç·£ç§»åˆ°ä¸­å¤®å€åŸŸ
                    move_distance = ((curr_x - prev_x)**2 + (curr_y - prev_y)**2)**0.5
                    if move_distance > 20:  # ç§»å‹•è·é›¢é–¾å€¼
                        is_ball_entry = True
                        entry_reason = f"é‚Šç·£ç§»å…¥ (å¾ {prev_x:.0f},{prev_y:.0f} åˆ° {curr_x:.0f},{curr_y:.0f})"
        
        # æª¢æŸ¥æ™‚é–“é–“éš”ä¸¦è¨˜éŒ„é€²å…¥é»
        if is_ball_entry and current_time - last_entry_time >= min_interval:
            ball_entry_times.append(current_time)
            last_entry_time = current_time
            print(f"ğŸ¾ åµæ¸¬åˆ°çƒé€²å…¥: {current_time:.2f}s - {entry_reason} (ä¿¡å¿ƒåº¦: {max_confidence:.3f})")
        
        # æ›´æ–°å‰ä¸€å¹€çš„ç‹€æ…‹
        previous_ball_detected = current_ball_detected
        previous_ball_position = ball_position
        frame_count += 1
        
        # é¡¯ç¤ºé€²åº¦
        if frame_count % (total_frames // 10) == 0:
            progress = (frame_count / total_frames) * 100
            print(f"   é€²åº¦: {progress:.1f}%")
    
    cap.release()
    
    print(f"âœ… åˆ†æå®Œæˆï¼åµæ¸¬åˆ° {len(ball_entry_times)} æ¬¡çƒé€²å…¥ç•«é¢")
    if ball_entry_times:
        print(f"ğŸ• çƒé€²å…¥æ™‚é–“é»: {[f'{t:.2f}s' for t in ball_entry_times]}")
    
    return ball_entry_times, detection_results

def segment_dual_videos_dynamic(side_video_path, deg45_video_path, output_folder, entry_times, start_offset=-0.5, end_padding=1.0):
    """
    æ ¹æ“šé€²å…¥æ™‚é–“é»å‹•æ…‹åˆ†å‰²å…©å€‹è§’åº¦çš„å½±ç‰‡ (æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹é€²å…¥é»åˆ°ä¸‹ä¸€å€‹é€²å…¥é»)
    
    åƒæ•¸:
    - side_video_path: å´é¢å½±ç‰‡è·¯å¾‘
    - deg45_video_path: 45åº¦å½±ç‰‡è·¯å¾‘
    - output_folder: è¼¸å‡ºè³‡æ–™å¤¾
    - entry_times: çƒé€²å…¥æ™‚é–“é»åˆ—è¡¨
    - start_offset: é–‹å§‹åç§»æ™‚é–“ (è² æ•¸è¡¨ç¤ºæå‰é–‹å§‹)
    - end_padding: æœ€å¾Œä¸€å€‹ç‰‡æ®µçš„é¡å¤–é•·åº¦
    """
    if not entry_times:
        print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°çƒé€²å…¥æ™‚é–“é»ï¼Œç„¡æ³•é€²è¡Œåˆ†å‰²")
        return []

    output_folder = Path(output_folder)
    output_folder.mkdir(parents=True, exist_ok=True)
    
    input_name = Path(side_video_path).stem.replace('_side', '').replace('__side', '')
    segment_info = []
    
    # ç²å–å½±ç‰‡ç¸½é•·åº¦
    cap = cv2.VideoCapture(str(side_video_path))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    video_duration = total_frames / fps
    cap.release()
    
    print(f"âœ‚ï¸ é–‹å§‹å‹•æ…‹åˆ†å‰²å…©å€‹è§’åº¦çš„å½±ç‰‡åˆ°: {output_folder}")
    print(f"ğŸ“¹ å´é¢å½±ç‰‡: {Path(side_video_path).name} (ç¸½é•·: {video_duration:.2f}ç§’)")
    print(f"ğŸ“¹ 45åº¦å½±ç‰‡: {Path(deg45_video_path).name}")
    print(f"ğŸ¯ å‹•æ…‹åˆ†å‰²é‚è¼¯: æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹çƒé€²å…¥é»åˆ°ä¸‹ä¸€å€‹çƒé€²å…¥é»")
    
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        segment_num = i + 1
        
        # è¨ˆç®—ç‰‡æ®µçµæŸæ™‚é–“
        if i < len(entry_times) - 1:
            # ä¸æ˜¯æœ€å¾Œä¸€å€‹ç‰‡æ®µï¼ŒçµæŸæ™‚é–“æ˜¯ä¸‹ä¸€å€‹é€²å…¥é»
            end_time = entry_times[i + 1] + start_offset
        else:
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µï¼Œä½¿ç”¨å›ºå®šé•·åº¦æˆ–å½±ç‰‡çµå°¾
            end_time = min(video_duration, entry_time + 4.0 + end_padding)
        
        # ç¢ºä¿ç‰‡æ®µé•·åº¦åˆç†
        segment_duration = max(1.0, end_time - start_time)  # æœ€å°‘1ç§’
        
        # å´é¢å½±ç‰‡åˆ†å‰²
        side_output_name = f"{input_name}_segment_{segment_num:02d}_side.mp4"
        side_output_path = output_folder / side_output_name
        
        # 45åº¦å½±ç‰‡åˆ†å‰²
        deg45_output_name = f"{input_name}_segment_{segment_num:02d}_45.mp4"
        deg45_output_path = output_folder / deg45_output_name
        
        print(f"ğŸ“½ï¸ ç‰‡æ®µ{segment_num}: {start_time:.2f}s - {end_time:.2f}s (æ™‚é•·: {segment_duration:.2f}s)")
        print(f"   çƒé€²å…¥æ™‚é–“: {entry_time:.2f}s")
        
        # åˆ†å‰²å´é¢å½±ç‰‡
        side_cmd = f'ffmpeg -i "{side_video_path}" -ss {start_time} -t {segment_duration} -c copy "{side_output_path}" -y -loglevel quiet'
        side_result = os.system(side_cmd)
        
        # åˆ†å‰²45åº¦å½±ç‰‡
        deg45_cmd = f'ffmpeg -i "{deg45_video_path}" -ss {start_time} -t {segment_duration} -c copy "{deg45_output_path}" -y -loglevel quiet'
        deg45_result = os.system(deg45_cmd)
        
        # æª¢æŸ¥çµæœ
        side_success = side_result == 0 and side_output_path.exists()
        deg45_success = deg45_result == 0 and deg45_output_path.exists()
        
        if side_success and deg45_success:
            side_size = os.path.getsize(side_output_path) / (1024*1024)
            deg45_size = os.path.getsize(deg45_output_path) / (1024*1024)
            
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'end_time': end_time,
                'duration': segment_duration,
                'side_video': str(side_output_path),
                'deg45_video': str(deg45_output_path),
                'side_size_mb': round(side_size, 2),
                'deg45_size_mb': round(deg45_size, 2),
                'success': True
            })
            print(f"   âœ… å®Œæˆ - å´é¢: {side_size:.1f}MB, 45åº¦: {deg45_size:.1f}MB")
        else:
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'end_time': end_time,
                'duration': segment_duration,
                'side_video': str(side_output_path),
                'deg45_video': str(deg45_output_path),
                'success': False,
                'error': f"Side: {'OK' if side_success else 'FAIL'}, 45deg: {'OK' if deg45_success else 'FAIL'}"
            })
            print(f"   âŒ å¤±æ•— - å´é¢: {'æˆåŠŸ' if side_success else 'å¤±æ•—'}, 45åº¦: {'æˆåŠŸ' if deg45_success else 'å¤±æ•—'}")
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ å‹•æ…‹åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(segment_info)} å€‹ç‰‡æ®µçµ„")
    
    return segment_info

def segment_dual_videos(side_video_path, deg45_video_path, output_folder, entry_times, segment_duration=4.0, start_offset=-0.5):
    """
    æ ¹æ“šé€²å…¥æ™‚é–“é»åŒæ­¥åˆ†å‰²å…©å€‹è§’åº¦çš„å½±ç‰‡ (å›ºå®šé•·åº¦ç‰ˆæœ¬)
    
    åƒæ•¸:
    - side_video_path: å´é¢å½±ç‰‡è·¯å¾‘
    - deg45_video_path: 45åº¦å½±ç‰‡è·¯å¾‘
    - output_folder: è¼¸å‡ºè³‡æ–™å¤¾
    - entry_times: çƒé€²å…¥æ™‚é–“é»åˆ—è¡¨
    - segment_duration: ç‰‡æ®µæ™‚é•·
    - start_offset: é–‹å§‹åç§»æ™‚é–“
    """
    if not entry_times:
        print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°çƒé€²å…¥æ™‚é–“é»ï¼Œç„¡æ³•é€²è¡Œåˆ†å‰²")
        return []

    output_folder = Path(output_folder)
    output_folder.mkdir(parents=True, exist_ok=True)
    
    input_name = Path(side_video_path).stem.replace('_side', '').replace('__side', '')
    segment_info = []
    
    print(f"âœ‚ï¸ é–‹å§‹åŒæ­¥åˆ†å‰²å…©å€‹è§’åº¦çš„å½±ç‰‡åˆ°: {output_folder}")
    print(f"ğŸ“¹ å´é¢å½±ç‰‡: {Path(side_video_path).name}")
    print(f"ğŸ“¹ 45åº¦å½±ç‰‡: {Path(deg45_video_path).name}")
    
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        segment_num = i + 1
        
        # å´é¢å½±ç‰‡åˆ†å‰²
        side_output_name = f"{input_name}_segment_{segment_num:02d}_side.mp4"
        side_output_path = output_folder / side_output_name
        
        # 45åº¦å½±ç‰‡åˆ†å‰²
        deg45_output_name = f"{input_name}_segment_{segment_num:02d}_45.mp4"
        deg45_output_path = output_folder / deg45_output_name
        
        print(f"ğŸ“½ï¸ åˆ†å‰²ç‰‡æ®µ {segment_num}: {start_time:.2f}s - {start_time + segment_duration:.2f}s")
        
        # åˆ†å‰²å´é¢å½±ç‰‡
        side_cmd = f'ffmpeg -i "{side_video_path}" -ss {start_time} -t {segment_duration} -c copy "{side_output_path}" -y -loglevel quiet'
        side_result = os.system(side_cmd)
        
        # åˆ†å‰²45åº¦å½±ç‰‡
        deg45_cmd = f'ffmpeg -i "{deg45_video_path}" -ss {start_time} -t {segment_duration} -c copy "{deg45_output_path}" -y -loglevel quiet'
        deg45_result = os.system(deg45_cmd)
        
        # æª¢æŸ¥çµæœ
        side_success = side_result == 0 and side_output_path.exists()
        deg45_success = deg45_result == 0 and deg45_output_path.exists()
        
        if side_success and deg45_success:
            side_size = os.path.getsize(side_output_path) / (1024*1024)
            deg45_size = os.path.getsize(deg45_output_path) / (1024*1024)
            
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'side_video': str(side_output_path),
                'deg45_video': str(deg45_output_path),
                'side_size_mb': round(side_size, 2),
                'deg45_size_mb': round(deg45_size, 2),
                'success': True
            })
            print(f"   âœ… å®Œæˆ - å´é¢: {side_size:.1f}MB, 45åº¦: {deg45_size:.1f}MB")
        else:
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'side_video': str(side_output_path),
                'deg45_video': str(deg45_output_path),
                'success': False,
                'error': f"Side: {'OK' if side_success else 'FAIL'}, 45deg: {'OK' if deg45_success else 'FAIL'}"
            })
            print(f"   âŒ å¤±æ•— - å´é¢: {'æˆåŠŸ' if side_success else 'å¤±æ•—'}, 45åº¦: {'æˆåŠŸ' if deg45_success else 'å¤±æ•—'}")
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ åŒæ­¥åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(segment_info)} å€‹ç‰‡æ®µçµ„")
    
    return segment_info

def segment_video_dynamic(input_path, output_folder, entry_times, start_offset=-0.5, end_padding=1.0):
    """
    æ ¹æ“šé€²å…¥æ™‚é–“é»å‹•æ…‹åˆ†å‰²å½±ç‰‡ (æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹é€²å…¥é»åˆ°ä¸‹ä¸€å€‹é€²å…¥é»)
    
    åƒæ•¸:
    - input_path: è¼¸å…¥å½±ç‰‡è·¯å¾‘
    - output_folder: è¼¸å‡ºè³‡æ–™å¤¾
    - entry_times: çƒé€²å…¥æ™‚é–“é»åˆ—è¡¨
    - start_offset: é–‹å§‹åç§»æ™‚é–“ (è² æ•¸è¡¨ç¤ºæå‰é–‹å§‹)
    - end_padding: æœ€å¾Œä¸€å€‹ç‰‡æ®µçš„é¡å¤–é•·åº¦
    """
    if not entry_times:
        print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°çƒé€²å…¥æ™‚é–“é»ï¼Œç„¡æ³•é€²è¡Œåˆ†å‰²")
        return []
    
    output_folder = Path(output_folder)
    output_folder.mkdir(parents=True, exist_ok=True)
    
    input_name = Path(input_path).stem
    segment_info = []
    
    # ç²å–å½±ç‰‡ç¸½é•·åº¦
    cap = cv2.VideoCapture(str(input_path))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    video_duration = total_frames / fps
    cap.release()
    
    print(f"âœ‚ï¸ é–‹å§‹å‹•æ…‹åˆ†å‰²å½±ç‰‡åˆ°: {output_folder}")
    print(f"ğŸ“¹ è¼¸å…¥å½±ç‰‡: {Path(input_path).name} (ç¸½é•·: {video_duration:.2f}ç§’)")
    print(f"ğŸ¯ å‹•æ…‹åˆ†å‰²é‚è¼¯: æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹çƒé€²å…¥é»åˆ°ä¸‹ä¸€å€‹çƒé€²å…¥é»")
    
    # æª¢æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨
    ffmpeg_available = check_ffmpeg_availability()
    
    if not ffmpeg_available:
        print("âš ï¸ FFmpeg ä¸å¯ç”¨ï¼Œä½¿ç”¨ OpenCV é€²è¡Œåˆ†å‰²")
        # æš«æ™‚ä½¿ç”¨å›ºå®šé•·åº¦çš„OpenCVåˆ†å‰²ï¼Œç¨å¾Œå¯ä»¥å¯¦ç¾å‹•æ…‹ç‰ˆæœ¬
        return segment_video_opencv(input_path, output_folder, entry_times, 4.0, start_offset)
    
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        segment_num = i + 1
        
        # è¨ˆç®—ç‰‡æ®µçµæŸæ™‚é–“
        if i < len(entry_times) - 1:
            # ä¸æ˜¯æœ€å¾Œä¸€å€‹ç‰‡æ®µï¼ŒçµæŸæ™‚é–“æ˜¯ä¸‹ä¸€å€‹é€²å…¥é»
            end_time = entry_times[i + 1] + start_offset
        else:
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µï¼Œä½¿ç”¨å›ºå®šé•·åº¦æˆ–å½±ç‰‡çµå°¾
            end_time = min(video_duration, entry_time + 4.0 + end_padding)
        
        # ç¢ºä¿ç‰‡æ®µé•·åº¦åˆç†
        segment_duration = max(1.0, end_time - start_time)  # æœ€å°‘1ç§’
        
        output_name = f"{input_name}_segment_{segment_num:02d}.mp4"
        output_path = output_folder / output_name
        
        print(f"ğŸ“½ï¸ ç‰‡æ®µ{segment_num}: {start_time:.2f}s - {end_time:.2f}s (æ™‚é•·: {segment_duration:.2f}s)")
        print(f"   çƒé€²å…¥æ™‚é–“: {entry_time:.2f}s")
        
        try:
            # ä½¿ç”¨ subprocess è€Œé os.systemï¼Œæä¾›æ›´å¥½çš„éŒ¯èª¤è™•ç†
            import subprocess
            cmd = [
                'ffmpeg', '-i', str(input_path),
                '-ss', str(start_time),
                '-t', str(segment_duration),
                '-c', 'copy',
                str(output_path),
                '-y', '-loglevel', 'error'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0 and output_path.exists():
                size_mb = os.path.getsize(output_path) / (1024*1024)
                segment_info.append({
                    'segment_id': segment_num,
                    'entry_time': entry_time,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': segment_duration,
                    'output_path': str(output_path),
                    'size_mb': round(size_mb, 2),
                    'success': True
                })
                print(f"   âœ… å®Œæˆ - å¤§å°: {size_mb:.1f}MB")
            else:
                error_msg = result.stderr if result.stderr else "æœªçŸ¥éŒ¯èª¤"
                segment_info.append({
                    'segment_id': segment_num,
                    'entry_time': entry_time,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': segment_duration,
                    'output_path': str(output_path),
                    'success': False,
                    'error': error_msg
                })
                print(f"   âŒ å¤±æ•— - éŒ¯èª¤: {error_msg}")
                
        except subprocess.TimeoutExpired:
            print(f"   âŒ è¶…æ™‚ - FFmpeg è™•ç†è¶…é30ç§’")
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'end_time': end_time,
                'duration': segment_duration,
                'output_path': str(output_path),
                'success': False,
                'error': "è™•ç†è¶…æ™‚"
            })
        except Exception as e:
            print(f"   âŒ éŒ¯èª¤ - {str(e)}")
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'end_time': end_time,
                'duration': segment_duration,
                'output_path': str(output_path),
                'success': False,
                'error': str(e)
            })
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ å‹•æ…‹åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(segment_info)} å€‹ç‰‡æ®µ")
    
    return segment_info

def segment_video(input_path, output_folder, entry_times, segment_duration=4.0, start_offset=-0.5):
    """
    æ ¹æ“šé€²å…¥æ™‚é–“é»åˆ†å‰²å½±ç‰‡ (å›ºå®šé•·åº¦ç‰ˆæœ¬)
    
    åƒæ•¸:
    - input_path: è¼¸å…¥å½±ç‰‡è·¯å¾‘
    - output_folder: è¼¸å‡ºè³‡æ–™å¤¾
    - entry_times: çƒé€²å…¥æ™‚é–“é»åˆ—è¡¨
    - segment_duration: ç‰‡æ®µæ™‚é•·
    - start_offset: é–‹å§‹åç§»æ™‚é–“
    """
    if not entry_times:
        print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°çƒé€²å…¥æ™‚é–“é»ï¼Œç„¡æ³•é€²è¡Œåˆ†å‰²")
        return []
    
    output_folder = Path(output_folder)
    output_folder.mkdir(parents=True, exist_ok=True)
    
    input_name = Path(input_path).stem
    segment_info = []
    
    print(f"âœ‚ï¸ é–‹å§‹åˆ†å‰²å½±ç‰‡åˆ°: {output_folder}")
    
    # æª¢æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨
    ffmpeg_available = check_ffmpeg_availability()
    
    if not ffmpeg_available:
        print("âš ï¸ FFmpeg ä¸å¯ç”¨ï¼Œä½¿ç”¨ OpenCV é€²è¡Œåˆ†å‰²")
        return segment_video_opencv(input_path, output_folder, entry_times, segment_duration, start_offset)
    
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        segment_num = i + 1
        
        output_name = f"{input_name}_segment_{segment_num:02d}.mp4"
        output_path = output_folder / output_name
        
        print(f"ğŸ“½ï¸ åˆ†å‰²ç‰‡æ®µ {segment_num}: {start_time:.2f}s - {start_time + segment_duration:.2f}s")
        
        try:
            # ä½¿ç”¨ subprocess è€Œé os.systemï¼Œæä¾›æ›´å¥½çš„éŒ¯èª¤è™•ç†
            import subprocess
            cmd = [
                'ffmpeg', '-i', str(input_path),
                '-ss', str(start_time),
                '-t', str(segment_duration),
                '-c', 'copy',
                str(output_path),
                '-y', '-loglevel', 'error'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and output_path.exists():
                file_size = os.path.getsize(output_path) / (1024*1024)  # MB
                segment_info.append({
                    'segment_id': segment_num,
                    'entry_time': entry_time,
                    'start_time': start_time,
                    'duration': segment_duration,
                    'output_file': str(output_path),
                    'file_size_mb': round(file_size, 2),
                    'success': True
                })
                print(f"   âœ… å®Œæˆ ({file_size:.1f} MB)")
            else:
                error_msg = result.stderr.strip() if result.stderr else "Unknown error"
                segment_info.append({
                    'segment_id': segment_num,
                    'entry_time': entry_time,
                    'start_time': start_time,
                    'duration': segment_duration,
                    'output_file': str(output_path),
                    'success': False,
                    'error': f'FFmpeg failed: {error_msg}'
                })
                print(f"   âŒ å¤±æ•—: {error_msg}")
                
        except subprocess.TimeoutExpired:
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'output_file': str(output_path),
                'success': False,
                'error': 'FFmpeg timeout'
            })
            print(f"   âŒ å¤±æ•—: è¶…æ™‚")
        except Exception as e:
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'output_file': str(output_path),
                'success': False,
                'error': f'Exception: {str(e)}'
            })
            print(f"   âŒ å¤±æ•—: {str(e)}")
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(entry_times)} å€‹ç‰‡æ®µ")
    
    return segment_info

def check_ffmpeg_availability():
    """æª¢æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨"""
    try:
        import subprocess
        result = subprocess.run(['ffmpeg', '-version'], 
                              capture_output=True, text=True, timeout=5)
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired, Exception):
        return False

def segment_video_opencv(input_path, output_folder, entry_times, segment_duration=4.0, start_offset=-0.5):
    """
    ä½¿ç”¨ OpenCV é€²è¡Œå½±ç‰‡åˆ†å‰²ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    """
    import cv2
    
    cap = cv2.VideoCapture(str(input_path))
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿè¼¸å…¥å½±ç‰‡")
        return []
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # å–å¾—å½±ç‰‡ç·¨è§£ç¢¼å™¨è³‡è¨Š
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ”„ ä½¿ç”¨ OpenCV é€²è¡Œå½±ç‰‡åˆ†å‰² ({fps:.1f} FPS, {frame_width}x{frame_height})")
    
    input_name = Path(input_path).stem
    segment_info = []
    
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        segment_num = i + 1
        
        start_frame = int(start_time * fps)
        end_frame = int((start_time + segment_duration) * fps)
        
        output_name = f"{input_name}_segment_{segment_num:02d}.mp4"
        output_path = output_folder / output_name
        
        print(f"ğŸ“½ï¸ åˆ†å‰²ç‰‡æ®µ {segment_num}: {start_time:.2f}s - {start_time + segment_duration:.2f}s")
        
        # è¨­ç½®å½±ç‰‡ä½ç½®åˆ°é–‹å§‹å¹€
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        # å‰µå»ºå½±ç‰‡å¯«å…¥å™¨
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (frame_width, frame_height))
        
        frames_written = 0
        current_frame = start_frame
        
        while current_frame < end_frame and current_frame < total_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            out.write(frame)
            frames_written += 1
            current_frame += 1
        
        out.release()
        
        if frames_written > 0 and output_path.exists():
            file_size = os.path.getsize(output_path) / (1024*1024)  # MB
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'output_file': str(output_path),
                'file_size_mb': round(file_size, 2),
                'frames_written': frames_written,
                'success': True
            })
            print(f"   âœ… å®Œæˆ ({file_size:.1f} MB, {frames_written} å¹€)")
        else:
            segment_info.append({
                'segment_id': segment_num,
                'entry_time': entry_time,
                'start_time': start_time,
                'duration': segment_duration,
                'output_file': str(output_path),
                'success': False,
                'error': 'OpenCV segmentation failed'
            })
            print(f"   âŒ å¤±æ•—")
    
    cap.release()
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ OpenCV åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(entry_times)} å€‹ç‰‡æ®µ")
    
    return segment_info
    
    successful = sum(1 for s in segment_info if s['success'])
    print(f"ğŸ¬ åˆ†å‰²å®Œæˆï¼æˆåŠŸ: {successful}/{len(segment_info)} å€‹ç‰‡æ®µ")
    
    return segment_info

def save_results(output_folder, input_video, entry_times, detection_results, segment_info, parameters):
    """å„²å­˜åˆ†æçµæœ"""
    output_folder = Path(output_folder)
    
    # å„²å­˜JSONçµæœ
    results = {
        'analysis_info': {
            'input_video': str(input_video),
            'analysis_time': datetime.now().isoformat(),
            'total_detections': len(detection_results),
            'ball_entries': len(entry_times)
        },
        'parameters': parameters,
        'ball_entry_times': entry_times,
        'segments': segment_info,
        'detection_summary': {
            'total_frames': len(detection_results),
            'frames_with_ball': sum(1 for r in detection_results if r['detected']),
            'max_confidence': max([r['confidence'] for r in detection_results]) if detection_results else 0,
            'avg_confidence': np.mean([r['confidence'] for r in detection_results]) if detection_results else 0
        }
    }
    
    json_file = output_folder / "analysis_results.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ çµæœå·²å„²å­˜: {json_file}")
    
    # å„²å­˜è©³ç´°çš„åµæ¸¬è³‡æ–™ (CSVæ ¼å¼)
    csv_file = output_folder / "detection_details.csv"
    with open(csv_file, 'w', encoding='utf-8') as f:
        f.write("frame,time_sec,detected,confidence\n")
        for result in detection_results:
            f.write(f"{result['frame']},{result['time']:.3f},{result['detected']},{result['confidence']:.4f}\n")
    
    print(f"ğŸ“Š è©³ç´°è³‡æ–™å·²å„²å­˜: {csv_file}")

def main():
    parser = argparse.ArgumentParser(description='å½±ç‰‡è‡ªå‹•åˆ†å‰²æ¸¬è©¦å·¥å…·')
    parser.add_argument('input_video', help='è¼¸å…¥å½±ç‰‡è·¯å¾‘ (æˆ–å´é¢å½±ç‰‡è·¯å¾‘)')
    parser.add_argument('--deg45-video', help='45åº¦è§’å½±ç‰‡è·¯å¾‘ (ç”¨æ–¼åŒæ­¥åˆ†å‰²)')
    parser.add_argument('--output', '-o', default='segments_output', help='è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('--confidence', '-c', type=float, default=0.5, help='åµæ¸¬ä¿¡å¿ƒåº¦é–¾å€¼')
    parser.add_argument('--duration', '-d', type=float, default=4.0, help='ç‰‡æ®µæ™‚é•·(ç§’)')
    parser.add_argument('--min-interval', '-i', type=float, default=2.0, help='æœ€å°é–“éš”æ™‚é–“(ç§’)')
    parser.add_argument('--start-offset', '-s', type=float, default=-0.5, help='é–‹å§‹åç§»æ™‚é–“(ç§’)')
    parser.add_argument('--model', '-m', default='model/tennisball_OD_v1.pt', help='YOLOæ¨¡å‹è·¯å¾‘')
    parser.add_argument('--simulate', action='store_true', help='ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼(ä¸éœ€è¦YOLOæ¨¡å‹)')
    parser.add_argument('--auto-find-pair', action='store_true', help='è‡ªå‹•å°‹æ‰¾é…å°å½±ç‰‡ (_side é…å° _45)')
    parser.add_argument('--no-visualization', action='store_true', help='ä¸ç”Ÿæˆåˆ†æåœ–è¡¨')
    parser.add_argument('--dynamic', action='store_true', help='å‹•æ…‹åˆ†å‰²æ¨¡å¼: æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹çƒé€²å…¥é»åˆ°ä¸‹ä¸€å€‹çƒé€²å…¥é»')
    parser.add_argument('--end-padding', type=float, default=1.0, help='æœ€å¾Œä¸€å€‹ç‰‡æ®µçš„é¡å¤–æ™‚é•·(ç§’, åƒ…å‹•æ…‹æ¨¡å¼)')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆ (æ¨¡æ“¬æ¨¡å¼ä¸‹è·³éæª¢æŸ¥)
    if not args.simulate and not os.path.exists(args.input_video):
        print(f"âŒ è¼¸å…¥å½±ç‰‡ä¸å­˜åœ¨: {args.input_video}")
        return 1
        
    # è‡ªå‹•å°‹æ‰¾é…å°å½±ç‰‡ (åƒ…åœ¨éæ¨¡æ“¬æ¨¡å¼ä¸‹)
    deg45_video = args.deg45_video
    if args.auto_find_pair and not deg45_video and not args.simulate:
        input_path = Path(args.input_video)
        if '_side' in input_path.stem:
            # å¾ side å½±ç‰‡å°‹æ‰¾å°æ‡‰çš„ 45 åº¦å½±ç‰‡
            deg45_name = input_path.stem.replace('_side', '_45').replace('__side', '__45') + input_path.suffix
            deg45_video = input_path.parent / deg45_name
            if deg45_video.exists():
                print(f"ğŸ” è‡ªå‹•æ‰¾åˆ°é…å°å½±ç‰‡: {deg45_video}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°é…å°çš„45åº¦å½±ç‰‡: {deg45_video}")
                deg45_video = None
        elif '_45' in input_path.stem or '__45' in input_path.stem:
            # å¾ 45 åº¦å½±ç‰‡å°‹æ‰¾å°æ‡‰çš„ side å½±ç‰‡
            side_name = input_path.stem.replace('_45', '_side').replace('__45', '__side') + input_path.suffix
            side_video = input_path.parent / side_name
            if side_video.exists():
                print(f"ğŸ” è‡ªå‹•æ‰¾åˆ°é…å°å½±ç‰‡: {side_video}")
                # äº¤æ›ï¼Œä»¥ side å½±ç‰‡ç‚ºä¸»è¦åˆ†æå°è±¡
                deg45_video = args.input_video
                args.input_video = str(side_video)
                print(f"ğŸ“ ä»¥å´é¢å½±ç‰‡ç‚ºä¸»è¦åˆ†æå°è±¡: {side_video}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°é…å°çš„å´é¢å½±ç‰‡: {side_video}")
                deg45_video = None
    
    # å¦‚æœæŒ‡å®šäº†é…å°å½±ç‰‡ï¼Œæª¢æŸ¥å…¶å­˜åœ¨æ€§ (æ¨¡æ“¬æ¨¡å¼ä¸‹è·³é)
    if deg45_video and not args.simulate and not os.path.exists(deg45_video):
        print(f"âŒ é…å°å½±ç‰‡ä¸å­˜åœ¨: {deg45_video}")
        return 1
    
    # è¼‰å…¥æ¨¡å‹
    model = None
    if not args.simulate and YOLO_AVAILABLE:
        if os.path.exists(args.model):
            print(f"ğŸ¤– è¼‰å…¥YOLOæ¨¡å‹: {args.model}")
            try:
                model = YOLO(args.model)
                print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                print("ğŸ”„ åˆ‡æ›åˆ°æ¨¡æ“¬æ¨¡å¼")
        else:
            print(f"âš ï¸ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {args.model}")
            print("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    else:
        print("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    
    # åˆ†æå½±ç‰‡
    try:
        entry_times, detection_results = detect_ball_entry_points(
            args.input_video, 
            model, 
            args.confidence, 
            args.min_interval
        )
        
        # åˆ†å‰²å½±ç‰‡
        if deg45_video:
            # é›™å½±ç‰‡åŒæ­¥åˆ†å‰²æ¨¡å¼
            print(f"ğŸ¯ é›™å½±ç‰‡åŒæ­¥åˆ†å‰²æ¨¡å¼")
            
            if args.dynamic:
                print(f"ğŸš€ ä½¿ç”¨å‹•æ…‹åˆ†å‰²æ¨¡å¼")
                segment_info = segment_dual_videos_dynamic(
                    args.input_video,  # å´é¢å½±ç‰‡ (ç”¨æ–¼åˆ†æ)
                    deg45_video,       # 45åº¦å½±ç‰‡
                    args.output,
                    entry_times,
                    args.start_offset,
                    args.end_padding
                )
            else:
                print(f"ğŸ“ ä½¿ç”¨å›ºå®šé•·åº¦åˆ†å‰²æ¨¡å¼")
                segment_info = segment_dual_videos(
                    args.input_video,  # å´é¢å½±ç‰‡ (ç”¨æ–¼åˆ†æ)
                    deg45_video,       # 45åº¦å½±ç‰‡
                    args.output,
                    entry_times,
                    args.duration,
                    args.start_offset
                )
        else:
            # å–®ä¸€å½±ç‰‡åˆ†å‰²æ¨¡å¼
            print(f"ğŸ¯ å–®ä¸€å½±ç‰‡åˆ†å‰²æ¨¡å¼")
            
            if args.dynamic:
                print(f"ğŸš€ ä½¿ç”¨å‹•æ…‹åˆ†å‰²æ¨¡å¼: æ¯å€‹ç‰‡æ®µå¾ä¸€å€‹çƒé€²å…¥é»åˆ°ä¸‹ä¸€å€‹çƒé€²å…¥é»")
                segment_info = segment_video_dynamic(
                    args.input_video,
                    args.output,
                    entry_times,
                    args.start_offset,
                    args.end_padding
                )
            else:
                print(f"ğŸ“ ä½¿ç”¨å›ºå®šé•·åº¦åˆ†å‰²æ¨¡å¼: æ¯å€‹ç‰‡æ®µ{args.duration}ç§’")
                segment_info = segment_video(
                    args.input_video,
                    args.output,
                    entry_times,
                    args.duration,
                    args.start_offset
                )
        
        # å„²å­˜çµæœ
        parameters = {
            'confidence_threshold': args.confidence,
            'segment_duration': args.duration,
            'min_interval': args.min_interval,
            'start_offset': args.start_offset,
            'model_path': args.model,
            'simulation_mode': args.simulate or not YOLO_AVAILABLE,
            'dynamic_mode': args.dynamic,
            'end_padding': args.end_padding if args.dynamic else None
        }
        
        save_results(
            args.output,
            args.input_video,
            entry_times,
            detection_results,
            segment_info,
            parameters
        )
        
        # å‰µå»ºåˆ†æå¯è¦–åŒ–åœ–è¡¨
        if not args.no_visualization:
            print("\nğŸ“Š å»ºç«‹åˆ†æå¯è¦–åŒ–...")
            visualization_path = create_analysis_visualization(
                detection_results,
                entry_times,
                args.input_video,
                args.confidence,
                args.start_offset
            )
        
        print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼")
        print(f"ğŸ“ æŸ¥çœ‹è¼¸å‡ºè³‡æ–™å¤¾: {Path(args.output).absolute()}")
        
    except Exception as e:
        print(f"âŒ è™•ç†å¤±æ•—: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())