#!/usr/bin/env python3
"""
å½±ç‰‡åˆ†å‰²è¨ºæ–·å·¥å…·
æª¢æŸ¥æª¢æ¸¬çµæœçš„æº–ç¢ºæ€§å’Œç‰‡æ®µå…§å®¹çš„æ­£ç¢ºæ€§
"""

import json
import cv2
import sys
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import numpy as np

def load_analysis_results(json_file):
    """è¼‰å…¥åˆ†æçµæœ"""
    with open(json_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_detection_quality(results):
    """åˆ†ææª¢æ¸¬å“è³ª"""
    print("ğŸ” æª¢æ¸¬å“è³ªåˆ†æ")
    print("="*50)
    
    entry_times = results.get('ball_entry_times', [])
    detection_details = results.get('detection_details', [])
    
    if not entry_times:
        print("âŒ æ²’æœ‰æª¢æ¸¬åˆ°çƒé€²å…¥æ™‚é–“é»")
        return
    
    print(f"ç¸½æª¢æ¸¬é»æ•¸: {len(entry_times)}")
    
    # åˆ†æé–“éš”åˆ†ä½ˆ
    if len(entry_times) > 1:
        intervals = [entry_times[i+1] - entry_times[i] for i in range(len(entry_times)-1)]
        print(f"\nğŸ“Š æ™‚é–“é–“éš”åˆ†æ:")
        print(f"  æœ€å°é–“éš”: {min(intervals):.2f}ç§’")
        print(f"  æœ€å¤§é–“éš”: {max(intervals):.2f}ç§’")
        print(f"  å¹³å‡é–“éš”: {np.mean(intervals):.2f}ç§’")
        print(f"  æ¨™æº–å·®: {np.std(intervals):.2f}ç§’")
        
        # æª¢æŸ¥å¯ç–‘çš„çŸ­é–“éš”
        suspicious_intervals = [i for i in intervals if i < 3.0]  # å°æ–¼3ç§’
        if suspicious_intervals:
            print(f"\nâš ï¸ å¯ç–‘çš„çŸ­é–“éš” (<3ç§’): {len(suspicious_intervals)}å€‹")
            for i, interval in enumerate(intervals):
                if interval < 3.0:
                    print(f"  é»{i+1}åˆ°{i+2}: {interval:.2f}ç§’")
    
    # åˆ†ææª¢æ¸¬ç´°ç¯€
    if detection_details:
        print(f"\nğŸ¯ æª¢æ¸¬ç´°ç¯€åˆ†æ:")
        for i, detail in enumerate(detection_details):
            time_point = detail.get('time', entry_times[i] if i < len(entry_times) else 'N/A')
            confidence = detail.get('confidence', 'N/A')
            position = detail.get('position', 'N/A')
            edge_zone = detail.get('edge_zone', 'N/A')
            
            print(f"  æª¢æ¸¬{i+1}: æ™‚é–“={time_point:.2f}s, ä¿¡å¿ƒåº¦={confidence:.3f}, é‚Šç·£å€={edge_zone}")

def check_video_segments(video_path, entry_times, duration=4.0, start_offset=-0.5):
    """æª¢æŸ¥å¯¦éš›çš„å½±ç‰‡ç‰‡æ®µå…§å®¹"""
    print(f"\nğŸ¬ å½±ç‰‡ç‰‡æ®µå…§å®¹æª¢æŸ¥")
    print("="*50)
    
    if not Path(video_path).exists():
        print(f"âŒ å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {video_path}")
        return
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ: {video_path}")
        return
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    video_duration = total_frames / fps
    
    print(f"ğŸ“¹ å½±ç‰‡è³‡è¨Š:")
    print(f"  æª”æ¡ˆ: {video_path}")
    print(f"  FPS: {fps:.2f}")
    print(f"  ç¸½å¹€æ•¸: {total_frames}")
    print(f"  ç¸½æ™‚é•·: {video_duration:.2f}ç§’")
    
    # æª¢æŸ¥æ¯å€‹ç‰‡æ®µ
    segments_info = []
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        end_time = min(video_duration, start_time + duration)
        actual_duration = end_time - start_time
        
        start_frame = int(start_time * fps)
        end_frame = int(end_time * fps)
        
        print(f"\n  ç‰‡æ®µ{i+1}:")
        print(f"    çƒé€²å…¥æ™‚é–“: {entry_time:.2f}s")
        print(f"    ç‰‡æ®µç¯„åœ: {start_time:.2f}s - {end_time:.2f}s")
        print(f"    å¯¦éš›é•·åº¦: {actual_duration:.2f}s")
        print(f"    å¹€ç¯„åœ: {start_frame} - {end_frame}")
        
        # å–æ¨£æª¢æŸ¥é—œéµå¹€
        key_frames = []
        sample_times = [start_time, entry_time, end_time - 0.5]  # é–‹å§‹ã€çƒé€²å…¥ã€çµæŸå‰
        
        for j, sample_time in enumerate(sample_times):
            frame_num = int(sample_time * fps)
            if 0 <= frame_num < total_frames:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = cap.read()
                if ret:
                    key_frames.append({
                        'time': sample_time,
                        'frame': frame_num,
                        'description': ['ç‰‡æ®µé–‹å§‹', 'çƒé€²å…¥é»', 'ç‰‡æ®µçµæŸ'][j]
                    })
        
        segments_info.append({
            'id': i + 1,
            'entry_time': entry_time,
            'start_time': start_time,
            'end_time': end_time,
            'duration': actual_duration,
            'key_frames': key_frames
        })
    
    cap.release()
    return segments_info

def create_timeline_visualization(entry_times, duration=4.0, start_offset=-0.5, output_file='segment_timeline.png'):
    """å‰µå»ºæ™‚é–“è»¸è¦–è¦ºåŒ–"""
    print(f"\nğŸ“Š å‰µå»ºæ™‚é–“è»¸è¦–è¦ºåŒ–: {output_file}")
    
    fig, ax = plt.subplots(figsize=(14, 6))
    
    # è¨­å®šé¡è‰²
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']
    
    # ç¹ªè£½ç‰‡æ®µ
    for i, entry_time in enumerate(entry_times):
        start_time = max(0, entry_time + start_offset)
        end_time = start_time + duration
        
        color = colors[i % len(colors)]
        
        # ç¹ªè£½ç‰‡æ®µçŸ©å½¢
        rect = Rectangle((start_time, i), duration, 0.8, 
                        facecolor=color, alpha=0.7, edgecolor='black', linewidth=1)
        ax.add_patch(rect)
        
        # æ¨™è¨˜çƒé€²å…¥é»
        ax.axvline(x=entry_time, color='red', linestyle='--', alpha=0.8, linewidth=2)
        ax.text(entry_time, i + 0.4, f'çƒ{i+1}\n{entry_time:.1f}s', 
               ha='center', va='center', fontsize=9, fontweight='bold')
        
        # ç‰‡æ®µæ¨™ç±¤
        ax.text(start_time + duration/2, i + 0.9, 
               f'ç‰‡æ®µ{i+1} ({duration}s)', ha='center', va='bottom', fontsize=10)
    
    # è¨­å®šåœ–è¡¨
    ax.set_xlim(-1, max(entry_times) + duration + 1)
    ax.set_ylim(-0.5, len(entry_times) + 0.5)
    ax.set_xlabel('æ™‚é–“ (ç§’)', fontsize=12)
    ax.set_ylabel('ç‰‡æ®µ', fontsize=12)
    ax.set_title('å½±ç‰‡åˆ†å‰²æ™‚é–“è»¸', fontsize=14, fontweight='bold')
    
    # è¨­å®šYè»¸æ¨™ç±¤
    ax.set_yticks(range(len(entry_times)))
    ax.set_yticklabels([f'ç‰‡æ®µ{i+1}' for i in range(len(entry_times))])
    
    # æ·»åŠ ç¶²æ ¼
    ax.grid(True, alpha=0.3)
    
    # æ·»åŠ åœ–ä¾‹
    legend_elements = [
        plt.Rectangle((0,0),1,1, facecolor='lightblue', alpha=0.7, label='å½±ç‰‡ç‰‡æ®µ'),
        plt.Line2D([0],[0], color='red', linestyle='--', label='çƒé€²å…¥é»')
    ]
    ax.legend(handles=legend_elements, loc='upper right')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ… æ™‚é–“è»¸è¦–è¦ºåŒ–å·²å„²å­˜: {output_file}")
    
    return output_file

def main():
    """ä¸»å‡½æ•¸"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python segment_diagnostics.py <analysis_results.json> [video_file]")
        print("\nç¯„ä¾‹:")
        print("  python segment_diagnostics.py test_enhanced_output/analysis_results.json")
        print("  python segment_diagnostics.py test_enhanced_output/analysis_results.json video.mp4")
        return 1
    
    json_file = sys.argv[1]
    video_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    if not Path(json_file).exists():
        print(f"âŒ åˆ†ææª”æ¡ˆä¸å­˜åœ¨: {json_file}")
        return 1
    
    # è¼‰å…¥åˆ†æçµæœ
    try:
        results = load_analysis_results(json_file)
        print(f"ğŸ“ è¼‰å…¥åˆ†æçµæœ: {json_file}")
    except Exception as e:
        print(f"âŒ è¼‰å…¥åˆ†æçµæœå¤±æ•—: {e}")
        return 1
    
    # åˆ†ææª¢æ¸¬å“è³ª
    analyze_detection_quality(results)
    
    # ç²å–åƒæ•¸
    entry_times = results.get('ball_entry_times', [])
    parameters = results.get('parameters', {})
    duration = parameters.get('segment_duration', 4.0)
    start_offset = parameters.get('start_offset', -0.5)
    
    # å‰µå»ºæ™‚é–“è»¸è¦–è¦ºåŒ–
    output_dir = Path(json_file).parent
    timeline_file = output_dir / 'segment_timeline_diagnostic.png'
    create_timeline_visualization(entry_times, duration, start_offset, str(timeline_file))
    
    # æª¢æŸ¥å½±ç‰‡ç‰‡æ®µï¼ˆå¦‚æœæä¾›å½±ç‰‡æª”æ¡ˆï¼‰
    if video_file:
        if Path(video_file).exists():
            check_video_segments(video_file, entry_times, duration, start_offset)
        else:
            print(f"âš ï¸ å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {video_file}")
            # å˜—è©¦åœ¨çµæœç›®éŒ„ä¸­å°‹æ‰¾å½±ç‰‡
            video_candidates = list(Path(json_file).parent.glob("*.mp4"))
            if video_candidates:
                video_file = str(video_candidates[0])
                print(f"ğŸ” æ‰¾åˆ°å€™é¸å½±ç‰‡: {video_file}")
                check_video_segments(video_file, entry_times, duration, start_offset)
    
    print(f"\nâœ… è¨ºæ–·å®Œæˆï¼")
    print(f"ğŸ“Š æ™‚é–“è»¸è¦–è¦ºåŒ–: {timeline_file}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())