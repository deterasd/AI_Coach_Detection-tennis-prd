"""
æœ€ç°¡é·ç§»é©—è­‰è…³æœ¬
åªéœ€è¦ ai_config.py å’Œ remote_lm_studio_config.py å°±èƒ½é‹è¡Œ
"""

def quick_migration_test():
    """å¿«é€Ÿæ¸¬è©¦é·ç§»æ˜¯å¦æˆåŠŸ"""
    print("ğŸ§ª å¿«é€Ÿé·ç§»æ¸¬è©¦")
    print("=" * 30)
    
    try:
        # æ¸¬è©¦ ai_config å°å…¥
        from ai_config import ai_config
        print("âœ… ai_config.py å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦å®¢æˆ¶ç«¯åˆå§‹åŒ–
        client = ai_config.get_client()
        if client:
            print("âœ… AI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # æ¸¬è©¦æ¨¡å‹åç¨±ç²å–
            model_name = ai_config.get_model_name()
            print(f"âœ… æ¨¡å‹åç¨±: {model_name}")
            
            # æ¸¬è©¦æä¾›è€…è­˜åˆ¥
            if ai_config.is_lm_studio():
                print("âœ… ä½¿ç”¨ LM Studio")
            else:
                print("âœ… ä½¿ç”¨ OpenAI API (è‡ªå‹•å›é€€)")
            
            # ç°¡å–® API æ¸¬è©¦
            try:
                completion = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": "æ¸¬è©¦"}],
                    max_tokens=10
                )
                print("âœ… API å‘¼å«æ¸¬è©¦æˆåŠŸ")
                return True
            except Exception as api_error:
                print(f"âš ï¸ API æ¸¬è©¦å¤±æ•—: {api_error}")
                return False
                
        else:
            print("âŒ AI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—")
            return False
            
    except ImportError as e:
        print(f"âŒ å°å…¥å¤±æ•—: {e}")
        print("ğŸ’¡ è«‹ç¢ºèªå·²è¤‡è£½ ai_config.py åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„")
        return False
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

def check_required_files():
    """æª¢æŸ¥å¿…è¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨"""
    import os
    
    print("ğŸ“ æª¢æŸ¥å¿…è¦æª”æ¡ˆ...")
    
    required_files = {
        'ai_config.py': 'AI é…ç½®ç®¡ç†æ ¸å¿ƒ',
        'remote_lm_studio_config.py': 'LM Studio é ç¨‹é…ç½®'
    }
    
    missing_files = []
    
    for filename, description in required_files.items():
        if os.path.exists(filename):
            print(f"âœ… {filename} ({description})")
        else:
            print(f"âŒ {filename} ({description}) - ç¼ºå°‘")
            missing_files.append(filename)
    
    return len(missing_files) == 0

def show_minimal_setup_guide():
    """é¡¯ç¤ºæœ€ç°¡è¨­ç½®æŒ‡å—"""
    print("\n" + "=" * 50)
    print("ğŸš€ æœ€ç°¡é·ç§»æŒ‡å—")
    print("=" * 50)
    print("\nğŸ“‹ åªéœ€è¦åšé€™äº›ï¼š")
    print("\n1ï¸âƒ£ è¤‡è£½æª”æ¡ˆåˆ°åŸå§‹å°ˆæ¡ˆï¼š")
    print("   - ai_config.py")
    print("   - remote_lm_studio_config.py")
    
    print("\n2ï¸âƒ£ ä¿®æ”¹ä¸€è¡Œç¨‹å¼ç¢¼ï¼š")
    print("   åœ¨ trajectory_gpt_single_feedback.py ä¸­ï¼š")
    print("   MODEL = model_config.MODEL")
    print("   æ”¹æˆï¼š")
    print("   MODEL = ai_config.get_model_name()")
    
    print("\n3ï¸âƒ£ è¨­ç½® LM Studioï¼š")
    print("   - å•Ÿå‹• LM Studio + è¼‰å…¥æ¨¡å‹")
    print("   - å•Ÿå‹• Local Server")
    print("   - æ›´æ–° remote_lm_studio_config.py ä¸­çš„ç¶²å€")
    
    print("\nâœ… å®Œæˆï¼ç³»çµ±æœƒè‡ªå‹•ï¼š")
    print("   - å‰µå»º config.json (å¦‚æœä¸å­˜åœ¨)")
    print("   - åµæ¸¬ LM Studio é€£æ¥")
    print("   - å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›åˆ° GPT")

def main():
    """ä¸»å‡½å¼"""
    print("ğŸ¯ æœ€ç°¡ GPT â†’ LM Studio é·ç§»æ¸¬è©¦")
    print("=" * 40)
    
    # æª¢æŸ¥æª”æ¡ˆ
    if not check_required_files():
        print("\nâŒ ç¼ºå°‘å¿…è¦æª”æ¡ˆ")
        show_minimal_setup_guide()
        return
    
    # åŸ·è¡Œæ¸¬è©¦
    success = quick_migration_test()
    
    if success:
        print("\nğŸ‰ é·ç§»æ¸¬è©¦é€šéï¼")
        print("ğŸ’¡ æ‚¨çš„å°ˆæ¡ˆå·²æˆåŠŸæ”¯æ´ LM Studio")
    else:
        print("\nâš ï¸ éœ€è¦æª¢æŸ¥è¨­ç½®")
        show_minimal_setup_guide()

if __name__ == "__main__":
    main()