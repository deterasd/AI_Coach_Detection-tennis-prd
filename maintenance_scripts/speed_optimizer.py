"""
AI é€Ÿåº¦å„ªåŒ–è¨­å®šæŒ‡å—
æä¾›ä¸åŒå ´æ™¯çš„æœ€ä½³é…ç½®åƒæ•¸
"""

import json
from datetime import datetime

# é è¨­é…ç½®çµ„åˆ
SPEED_CONFIGS = {
    "ultra_fast": {
        "name": "æ¥µé€Ÿæ¨¡å¼",
        "description": "æœ€å¿«é€Ÿåº¦ï¼Œé©åˆå¿«é€Ÿæ¸¬è©¦",
        "config": {
            "temperature": 0.1,     # æ¥µä½æº«åº¦ï¼Œæœ€ç¢ºå®šæ€§
            "max_tokens": 30,       # æ¥µå°‘ tokenï¼Œåªè¼¸å‡ºé—œéµå»ºè­°
            "top_p": 0.7,          # é™åˆ¶å€™é¸è©å½™
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "expected_speed": "0.5-1 ç§’"
    },
    
    "fast": {
        "name": "å¿«é€Ÿæ¨¡å¼",
        "description": "å¹³è¡¡é€Ÿåº¦å’Œå“è³ª",
        "config": {
            "temperature": 0.3,     # ä½æº«åº¦ï¼Œè¼ƒç¢ºå®š
            "max_tokens": 50,       # çŸ­å›æ‡‰
            "top_p": 0.8,          # é©ä¸­çš„è©å½™é¸æ“‡
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "expected_speed": "1-1.5 ç§’"
    },
    
    "balanced": {
        "name": "å¹³è¡¡æ¨¡å¼",
        "description": "é€Ÿåº¦èˆ‡å“è³ªå…¼é¡§",
        "config": {
            "temperature": 0.5,     # ä¸­ç­‰æº«åº¦
            "max_tokens": 80,       # ä¸­ç­‰é•·åº¦
            "top_p": 0.9,          # è¼ƒå¤šè©å½™é¸æ“‡
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "expected_speed": "1.5-2 ç§’"
    },
    
    "quality": {
        "name": "å“è³ªæ¨¡å¼",
        "description": "é‡è¦–å›æ‡‰å“è³ªï¼Œé€Ÿåº¦è¼ƒæ…¢",
        "config": {
            "temperature": 0.7,     # è¼ƒé«˜æº«åº¦ï¼Œæ›´æœ‰å‰µæ„
            "max_tokens": 120,      # è¼ƒé•·å›æ‡‰
            "top_p": 0.95,         # æ›´å¤šè©å½™é¸æ“‡
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1
        },
        "expected_speed": "2-3 ç§’"
    }
}

def apply_speed_config(mode="fast"):
    """æ‡‰ç”¨é€Ÿåº¦é…ç½®åˆ° config.json"""
    if mode not in SPEED_CONFIGS:
        print(f"âŒ ä¸æ”¯æ´çš„æ¨¡å¼: {mode}")
        print(f"æ”¯æ´çš„æ¨¡å¼: {', '.join(SPEED_CONFIGS.keys())}")
        return False
    
    speed_config = SPEED_CONFIGS[mode]
    
    try:
        # è®€å–ç¾æœ‰é…ç½®
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æ›´æ–° AI æ¨¡å‹é…ç½®
        if "ai_model" not in config:
            config["ai_model"] = {}
        
        # æ‡‰ç”¨é€Ÿåº¦é…ç½®
        config["ai_model"].update(speed_config["config"])
        config["last_updated"] = datetime.now().strftime("%Y-%m-%d")
        
        # ä¿å­˜é…ç½®
        with open('config.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å·²æ‡‰ç”¨ {speed_config['name']}")
        print(f"ğŸ“ {speed_config['description']}")
        print(f"â±ï¸ é æœŸé€Ÿåº¦: {speed_config['expected_speed']}")
        print("\nğŸ“‹ é…ç½®åƒæ•¸:")
        for key, value in speed_config["config"].items():
            print(f"   {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®å¤±æ•—: {e}")
        return False

def show_speed_tips():
    """é¡¯ç¤ºé€Ÿåº¦å„ªåŒ–æŠ€å·§"""
    print("ğŸš€ AI é€Ÿåº¦å„ªåŒ–æŠ€å·§")
    print("=" * 50)
    print("\nğŸ“Š åƒæ•¸èªªæ˜:")
    print("   â€¢ temperature: 0.1-0.3 (ä½) = å¿«é€Ÿä½†è¼ƒæ­»æ¿")
    print("   â€¢              0.4-0.6 (ä¸­) = å¹³è¡¡é€Ÿåº¦èˆ‡å‰µæ„")
    print("   â€¢              0.7-1.0 (é«˜) = æ…¢ä½†æ›´æœ‰å‰µæ„")
    print("")
    print("   â€¢ max_tokens:  30-50 (ä½) = æ¥µé€Ÿï¼Œç°¡çŸ­å›æ‡‰")
    print("   â€¢              60-100 (ä¸­) = å¹³è¡¡é•·åº¦")
    print("   â€¢              120+ (é«˜) = è©³ç´°ä½†æ…¢")
    print("")
    print("   â€¢ top_p:       0.6-0.8 (ä½) = å¿«é€Ÿï¼Œè¼ƒç¢ºå®š")
    print("   â€¢              0.8-0.9 (ä¸­) = å¹³è¡¡")
    print("   â€¢              0.9-1.0 (é«˜) = æ…¢ï¼Œæ›´å¤šæ¨£æ€§")
    
    print("\nğŸ¯ é‡å°ä¸åŒæ¨¡å‹çš„å»ºè­°:")
    print("   LM Studio (æœ¬åœ°):")
    print("   - å°æ¨¡å‹ (7B): temperature=0.2, max_tokens=40")
    print("   - ä¸­æ¨¡å‹ (13B): temperature=0.3, max_tokens=60")
    print("   - å¤§æ¨¡å‹ (30B+): temperature=0.4, max_tokens=80")
    print("")
    print("   OpenAI API:")
    print("   - gpt-4o-mini: temperature=0.3, max_tokens=50")
    print("   - gpt-4o: temperature=0.5, max_tokens=80")
    
    print("\nğŸ’¡ é¡å¤–å„ªåŒ–å»ºè­°:")
    print("   1. ä½¿ç”¨ LM Studio æ¯” OpenAI æ›´å¿« (æœ¬åœ°é‹ç®—)")
    print("   2. é¸æ“‡è¼ƒå°çš„æ¨¡å‹ (7B æ¯” 13B å¿«)")
    print("   3. ä½¿ç”¨ GPU åŠ é€Ÿ (CUDA/Metal)")
    print("   4. é—œé–‰ä¸å¿…è¦çš„è™•ç†æ­¥é©Ÿ")
    print("   5. ç°¡åŒ–æç¤ºè©å…§å®¹")

def main():
    """ä¸»å‡½å¼"""
    import sys
    
    if len(sys.argv) < 2:
        print("ğŸš€ AI é€Ÿåº¦å„ªåŒ–å·¥å…·")
        print("=" * 30)
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("   python speed_optimizer.py [æ¨¡å¼]")
        print("\nå¯ç”¨æ¨¡å¼:")
        for key, config in SPEED_CONFIGS.items():
            print(f"   {key:<12} - {config['name']} ({config['expected_speed']})")
        print("   tips         - é¡¯ç¤ºå„ªåŒ–æŠ€å·§")
        return
    
    mode = sys.argv[1].lower()
    
    if mode == "tips":
        show_speed_tips()
    elif mode in SPEED_CONFIGS:
        success = apply_speed_config(mode)
        if success:
            print("\nğŸ’¡ æç¤º:")
            print("   é‡æ–°åŸ·è¡Œç¨‹å¼ä»¥å¥—ç”¨æ–°è¨­å®š")
            print("   åŸ·è¡Œ python test_ai_switch.py é©—è­‰é€Ÿåº¦")
    else:
        print(f"âŒ ä¸æ”¯æ´çš„æ¨¡å¼: {mode}")
        main()

if __name__ == "__main__":
    main()