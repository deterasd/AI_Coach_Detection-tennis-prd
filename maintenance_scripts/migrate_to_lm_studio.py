"""
è‡ªå‹•é·ç§»è…³æœ¬ï¼šå°‡å°ˆæ¡ˆå¾ OpenAI GPT åˆ‡æ›åˆ° LM Studio
ä½¿ç”¨æ–¹æ³•ï¼špython migrate_to_lm_studio.py
"""

import os
import shutil
from datetime import datetime

def backup_file(filepath):
    """å‚™ä»½æª”æ¡ˆ"""
    if os.path.exists(filepath):
        backup_path = f"{filepath}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(filepath, backup_path)
        print(f"âœ… å·²å‚™ä»½: {os.path.basename(filepath)} -> {os.path.basename(backup_path)}")
        return True
    return False

def modify_trajectory_gpt():
    """ä¿®æ”¹ trajectory_gpt.py"""
    filepath = "trajectory_gpt.py"
    
    if not os.path.exists(filepath):
        print(f"âš ï¸  æ‰¾ä¸åˆ° {filepath}ï¼Œè·³é")
        return
    
    backup_file(filepath)
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“ä¿®æ”¹é
    if 'from ai_config import ai_config' in content:
        print(f"âœ… {filepath} å·²ç¶“ä½¿ç”¨ ai_configï¼Œç„¡éœ€ä¿®æ”¹")
        return
    
    # æ›¿æ› import
    content = content.replace(
        'from openai import OpenAI\nimport pandas as pd \nimport single_feedback.prompt as prompt, single_feedback.model_config as model_config\nfrom open_ai_key import api_key',
        'from openai import OpenAI\nimport pandas as pd \nimport single_feedback.prompt as prompt, single_feedback.model_config as model_config\nfrom ai_config import ai_config'
    )
    
    # æ›¿æ› client åˆå§‹åŒ–
    content = content.replace(
        'self.client = OpenAI(api_key=api_key)',
        'self.client = ai_config.get_client()'
    )
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… å·²ä¿®æ”¹: {filepath}")

def modify_trajectory_gpt_overall_feedback():
    """ä¿®æ”¹ trajectory_gpt_overall_feedback.py"""
    filepath = "trajectory_gpt_overall_feedback.py"
    
    if not os.path.exists(filepath):
        print(f"âš ï¸  æ‰¾ä¸åˆ° {filepath}ï¼Œè·³é")
        return
    
    backup_file(filepath)
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥æ˜¯å¦å·²ç¶“ä¿®æ”¹é
    if 'from ai_config import ai_config' in content:
        print(f"âœ… {filepath} å·²ç¶“ä½¿ç”¨ ai_configï¼Œç„¡éœ€ä¿®æ”¹")
        return
    
    # æ›¿æ› import
    content = content.replace(
        'from open_ai_key import api_key\n\n# --- å…¨åŸŸè¨­å®š ---\nclient = OpenAI(api_key=api_key)',
        'from ai_config import ai_config\n\n# --- å…¨åŸŸè¨­å®š ---\nclient = ai_config.get_client()'
    )
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… å·²ä¿®æ”¹: {filepath}")

def check_required_files():
    """æª¢æŸ¥å¿…è¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨"""
    print("\n=== æª¢æŸ¥å¿…è¦æª”æ¡ˆ ===")
    
    required_files = {
        'ai_config.py': 'è‡ªå‹•åˆ‡æ›ç®¡ç†å™¨',
        'remote_lm_studio_config.py': 'é ç¨‹ LM Studio é…ç½®',
        'single_feedback/model_config.py': 'æ¨¡å‹é…ç½®'
    }
    
    missing_files = []
    
    for filepath, description in required_files.items():
        if os.path.exists(filepath):
            print(f"âœ… {filepath} ({description})")
        else:
            print(f"âŒ ç¼ºå°‘: {filepath} ({description})")
            missing_files.append(filepath)
    
    return len(missing_files) == 0

def show_next_steps():
    """é¡¯ç¤ºå¾ŒçºŒæ­¥é©Ÿ"""
    print("\n" + "="*60)
    print("ğŸ‰ é·ç§»å®Œæˆï¼")
    print("="*60)
    print("\nğŸ“‹ å¾ŒçºŒæ­¥é©Ÿï¼š")
    print("\n1ï¸âƒ£ å•Ÿå‹• LM Studio")
    print("   - è¼‰å…¥æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼šgoogle/gemma-3n-e4bï¼‰")
    print("   - å•Ÿå‹• Local Server (é è¨­ port 1234)")
    
    print("\n2ï¸âƒ£ å•Ÿå‹• ngrok")
    print("   - åŸ·è¡Œ: ngrok http 1234")
    print("   - è¤‡è£½ ngrok æä¾›çš„ç¶²å€")
    
    print("\n3ï¸âƒ£ æ›´æ–°é…ç½®")
    print("   - ç·¨è¼¯ remote_lm_studio_config.py")
    print("   - å°‡ REMOTE_LM_STUDIO_URL æ”¹æˆæ‚¨çš„ ngrok ç¶²å€")
    print("   - æ ¼å¼: https://your-url.ngrok-free.dev/v1")
    
    print("\n4ï¸âƒ£ é©—è­‰è¨­å®š")
    print("   - åŸ·è¡Œ: python test_lm_studio_feedback.py")
    print("   - ç¢ºèªçœ‹åˆ° âœ… å·²é€£æ¥åˆ° LM Studio æœå‹™å™¨")
    
    print("\n5ï¸âƒ£ æ¸¬è©¦å®Œæ•´æµç¨‹")
    print("   - åŸ·è¡Œ: python test_gpt_feedback_quick.py")
    print("   - ç¢ºèªå›é¥‹ç”Ÿæˆæ­£å¸¸")
    
    print("\nğŸ’¡ æç¤ºï¼š")
    print("   - å¦‚æœ LM Studio ç„¡æ³•é€£æ¥ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ‡æ›åˆ° OpenAI API")
    print("   - æ‰€æœ‰åŸå§‹æª”æ¡ˆéƒ½å·²å‚™ä»½ï¼ˆ.backup_* æª”æ¡ˆï¼‰")
    print("   - å¦‚éœ€é‚„åŸï¼Œè«‹åˆªé™¤ä¿®æ”¹å¾Œçš„æª”æ¡ˆï¼Œä¸¦ç§»é™¤ .backup å‰¯æª”å")
    print("\n" + "="*60)

def main():
    print("="*60)
    print("ğŸ”„ é–‹å§‹é·ç§»å°ˆæ¡ˆåˆ° LM Studio")
    print("="*60)
    
    # æª¢æŸ¥å¿…è¦æª”æ¡ˆ
    if not check_required_files():
        print("\nâŒ ç¼ºå°‘å¿…è¦æª”æ¡ˆï¼Œè«‹å…ˆç¢ºä¿ä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ï¼š")
        print("   - ai_config.py")
        print("   - remote_lm_studio_config.py")
        print("   - single_feedback/model_config.py")
        return
    
    print("\n=== é–‹å§‹ä¿®æ”¹æª”æ¡ˆ ===")
    
    # ä¿®æ”¹å„å€‹æª”æ¡ˆ
    modify_trajectory_gpt()
    modify_trajectory_gpt_overall_feedback()
    
    # æª¢æŸ¥ trajectory_gpt_single_feedback.py
    if os.path.exists("trajectory_gpt_single_feedback.py"):
        with open("trajectory_gpt_single_feedback.py", 'r', encoding='utf-8') as f:
            content = f.read()
            if 'from ai_config import ai_config' in content:
                print("âœ… trajectory_gpt_single_feedback.py å·²ç¶“ä½¿ç”¨ ai_config")
            else:
                print("âš ï¸  trajectory_gpt_single_feedback.py éœ€è¦æ‰‹å‹•æª¢æŸ¥")
    
    # é¡¯ç¤ºå¾ŒçºŒæ­¥é©Ÿ
    show_next_steps()

if __name__ == "__main__":
    main()
