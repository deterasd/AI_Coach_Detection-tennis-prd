"""
Step 6: æ™‚é–“å¹³æ»‘åº¦é©—è­‰åˆ†æ
é©—è­‰ 3D è»Œè·¡åœ¨æ™‚é–“ç¶­åº¦çš„é€£çºŒæ€§å’Œå¹³æ»‘åº¦

åŠŸèƒ½ï¼š
  1. é€Ÿåº¦è®ŠåŒ–ç‡ï¼ˆä¸€éšå°æ•¸ï¼‰
  2. åŠ é€Ÿåº¦ç•°å¸¸æª¢æ¸¬ï¼ˆäºŒéšå°æ•¸ï¼‰
  3. æ–¹å‘çªè®Šæª¢æ¸¬
  4. ç•°å¸¸è·³èºæª¢æ¸¬
  5. å¹³æ»‘åº¦åˆ†æ
  6. é »åŸŸåˆ†æï¼ˆFFTï¼‰
  7. æ–¹å‘é€£çºŒæ€§å¢å¼·æª¢æ¸¬
"""

import json
import numpy as np
from numpy.linalg import norm
from datetime import datetime
import sys

# å¼•å…¥å…±ç”¨æ¨¡çµ„
from .utils import (
    get_keypoint_safely,
    calculate_distance,
    load_json_file,
    save_json_results,
    calculate_cv,
    detect_outliers_zscore,
    generate_output_path,
)
from config import load_config, ValidationConfig


# ========================================================
# æ ¸å¿ƒåˆ†æå‡½æ•¸
# ========================================================

def analyze_velocity_changes(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†æé€Ÿåº¦è®ŠåŒ–ç‡ï¼ˆä¸€éšå°æ•¸ï¼‰
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: é€Ÿåº¦åˆ†æçµæœ
    """
    fps = config.fps  # çµ±ä¸€ä½¿ç”¨ fps åƒæ•¸
    joint_velocities = {}
    
    for joint_name in ["left_wrist", "right_wrist", "nose"]:
        positions = []
        
        for frame in data:
            pos = get_keypoint_safely(frame, joint_name)
            if pos is not None:
                positions.append(pos)
            else:
                positions.append(None)
        
        velocities = []
        for i in range(1, len(positions)):
            if positions[i] is not None and positions[i - 1] is not None:
                disp = positions[i] - positions[i - 1]
                vel = norm(disp) * fps  # mm/s
                velocities.append(vel)
        
        if velocities:
            arr = np.array(velocities, dtype=float)
            joint_velocities[joint_name] = {
                "mean_velocity_mm_s": float(np.mean(arr)),
                "max_velocity_mm_s": float(np.max(arr)),
                "std_velocity_mm_s": float(np.std(arr)),
                "cv_percent": calculate_cv(arr),
                "sample_count": len(arr)
            }
    
    return joint_velocities


def analyze_acceleration_anomalies(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†æåŠ é€Ÿåº¦ç•°å¸¸ï¼ˆäºŒéšå°æ•¸ï¼‰
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: åŠ é€Ÿåº¦ç•°å¸¸åˆ†æçµæœ
    """
    fps = config.fps
    joint_name = "right_wrist"
    
    positions = []
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            positions.append(pos)
        else:
            positions.append(None)
    
    velocities = []
    for i in range(1, len(positions)):
        if positions[i] is not None and positions[i - 1] is not None:
            disp = positions[i] - positions[i - 1]
            vel = disp * fps  # mm/s
            velocities.append(vel)
        else:
            velocities.append(None)
    
    accelerations = []
    for i in range(1, len(velocities)):
        if velocities[i] is not None and velocities[i - 1] is not None:
            acc = (velocities[i] - velocities[i - 1]) * fps  # mm/sÂ²
            acc_magnitude = norm(acc)
            accelerations.append(acc_magnitude)
    
    if not accelerations:
        return {}
    
    arr = np.array(accelerations, dtype=float)
    outlier_indices, outlier_mask = detect_outliers_zscore(arr, config.acceleration_sigma)
    
    # æ”¶é›†ç•°å¸¸è©³æƒ…
    outlier_details = []
    for idx in outlier_indices:
        outlier_details.append({
            "frame": int(idx + 1),  # +1 å› ç‚ºåŠ é€Ÿåº¦å¾ç¬¬2å¹€é–‹å§‹
            "acceleration": float(arr[idx])
        })
    
    return {
        "joint": joint_name,
        "mean_acceleration_mm_s2": float(np.mean(arr)),
        "max_acceleration_mm_s2": float(np.max(arr)),
        "std_acceleration_mm_s2": float(np.std(arr)),
        "outlier_count": len(outlier_indices),
        "outlier_rate": float(len(outlier_indices) / len(arr) * 100),
        "sample_count": len(arr),
        "outlier_details": outlier_details
    }


def analyze_direction_changes(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†ææ–¹å‘çªè®Š
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: æ–¹å‘çªè®Šåˆ†æçµæœ
    """
    joint_name = "right_wrist"
    
    positions = []
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            positions.append(pos)
        else:
            positions.append(None)
    
    direction_vectors = []
    for i in range(1, len(positions)):
        if positions[i] is not None and positions[i - 1] is not None:
            vec = positions[i] - positions[i - 1]
            direction_vectors.append(vec)
        else:
            direction_vectors.append(None)
    
    direction_changes = []
    sudden_change_count = 0
    sudden_changes = []
    
    for i in range(1, len(direction_vectors)):
        if direction_vectors[i] is not None and direction_vectors[i - 1] is not None:
            v1 = direction_vectors[i - 1]
            v2 = direction_vectors[i]
            
            # é¿å…é›¶å‘é‡
            n1, n2 = norm(v1), norm(v2)
            if n1 > config.epsilon and n2 > config.epsilon:
                cos_theta = np.dot(v1, v2) / (n1 * n2)
                cos_theta = np.clip(cos_theta, -1.0, 1.0)
                angle_deg = float(np.degrees(np.arccos(cos_theta)))
                direction_changes.append(angle_deg)
                
                if angle_deg > config.direction_change_sudden:
                    sudden_change_count += 1
                    sudden_changes.append({
                        "frame": int(i + 1),  # +1 å› ç‚ºæ–¹å‘è®ŠåŒ–å¾ç¬¬2å¹€é–‹å§‹
                        "angle_change": float(angle_deg)
                    })
    
    if not direction_changes:
        return {}
    
    arr = np.array(direction_changes, dtype=float)
    
    return {
        "joint": joint_name,
        "mean_angle_change_deg": float(np.mean(arr)),
        "max_angle_change_deg": float(np.max(arr)),
        "std_angle_change_deg": float(np.std(arr)),
        "sudden_change_count": sudden_change_count,
        "sudden_change_rate": float(sudden_change_count / len(arr) * 100),
        "sample_count": len(arr),
        "sudden_changes": sudden_changes
    }


def analyze_jump_anomalies(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†æç•°å¸¸è·³èº
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: è·³èºç•°å¸¸åˆ†æçµæœ
    """
    joint_name = "right_wrist"
    
    positions = []
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            positions.append(pos)
        else:
            positions.append(None)
    
    displacements = []
    for i in range(1, len(positions)):
        if positions[i] is not None and positions[i - 1] is not None:
            disp = calculate_distance(positions[i - 1], positions[i])
            if disp is not None:
                displacements.append(disp)
    
    if not displacements:
        return {}
    
    arr = np.array(displacements, dtype=float)
    outlier_indices, outlier_mask = detect_outliers_zscore(arr, config.jump_detection_sigma)
    
    # ç›´æ¥æª¢æ¸¬è¶…éé–¾å€¼çš„è·³èºä¸¦æ”¶é›†è©³æƒ…
    large_jumps = []
    for i, disp in enumerate(arr):
        if disp > config.max_frame_displacement:
            large_jumps.append({
                "frame": int(i + 1),  # +1 å› ç‚ºä½ç§»å¾ç¬¬2å¹€é–‹å§‹
                "displacement": float(disp)
            })
    
    large_jump_count = len(large_jumps)
    
    return {
        "joint": joint_name,
        "mean_displacement_mm": float(np.mean(arr)),
        "max_displacement_mm": float(np.max(arr)),
        "std_displacement_mm": float(np.std(arr)),
        "zscore_outlier_count": len(outlier_indices),
        "large_jump_count": large_jump_count,
        "large_jump_rate": float(large_jump_count / len(arr) * 100),
        "sample_count": len(arr),
        "large_jumps": large_jumps
    }


def analyze_smoothness(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†ææ•´é«”å¹³æ»‘åº¦
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: å¹³æ»‘åº¦åˆ†æçµæœ
    """
    joint_name = "right_wrist"
    
    positions = []
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            positions.append(pos)
    
    if len(positions) < 3:
        return {}
    
    # äºŒéšå·®åˆ†ï¼ˆæ›²ç‡è®ŠåŒ–ï¼‰
    second_diffs = []
    for i in range(1, len(positions) - 1):
        diff2 = positions[i + 1] - 2 * positions[i] + positions[i - 1]
        second_diffs.append(norm(diff2))
    
    if not second_diffs:
        return {}
    
    arr = np.array(second_diffs, dtype=float)
    
    return {
        "joint": joint_name,
        "mean_second_diff_mm": float(np.mean(arr)),
        "std_second_diff_mm": float(np.std(arr)),
        "max_second_diff_mm": float(np.max(arr)),
        "sample_count": len(arr)
    }


def analyze_frequency_domain(data: list, config: ValidationConfig) -> dict:
    """
    åˆ†æé »åŸŸç‰¹å¾µï¼ˆæ–°å¢ - FFTï¼‰
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: é »åŸŸåˆ†æçµæœ
    """
    # ä½¿ç”¨é…ç½®çš„é—œç¯€ï¼Œé è¨­ç‚º right_wrist
    joint_name = getattr(config, 'fft_analysis_joint', 'right_wrist')
    
    # æå– X, Y, Z è»Œè·¡
    x_positions = []
    y_positions = []
    z_positions = []
    
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            x_positions.append(pos[0])
            y_positions.append(pos[1])
            z_positions.append(pos[2])
    
    if len(x_positions) < 10:
        return {}
    
    def fft_analysis(signal):
        n = len(signal)
        fft_result = np.fft.fft(signal)
        freqs = np.fft.fftfreq(n, 1.0 / config.fps)
        
        # åªå–æ­£é »ç‡éƒ¨åˆ†
        positive_freqs = freqs[:n // 2]
        magnitude = np.abs(fft_result[:n // 2])
        
        # ä¸»é »ç‡
        dominant_freq_idx = np.argmax(magnitude[1:]) + 1  # æ’é™¤ DC åˆ†é‡
        dominant_freq = float(positive_freqs[dominant_freq_idx])
        
        # é«˜é »èƒ½é‡ä½”æ¯”
        high_freq_threshold = config.high_frequency_threshold  # Hz
        high_freq_mask = positive_freqs > high_freq_threshold
        high_freq_energy = float(np.sum(magnitude[high_freq_mask] ** 2))
        total_energy = float(np.sum(magnitude[1:] ** 2))  # æ’é™¤ DC
        high_freq_ratio = high_freq_energy / total_energy if total_energy > 0 else 0.0
        
        return {
            "dominant_frequency_hz": dominant_freq,
            "high_frequency_ratio": high_freq_ratio
        }
    
    x_fft = fft_analysis(x_positions)
    y_fft = fft_analysis(y_positions)
    z_fft = fft_analysis(z_positions)
    
    return {
        "joint": joint_name,
        "x_axis": x_fft,
        "y_axis": y_fft,
        "z_axis": z_fft,
        "sample_count": len(x_positions)
    }


def analyze_direction_continuity_enhanced(data: list, config: ValidationConfig) -> dict:
    """
    å¢å¼·çš„æ–¹å‘é€£çºŒæ€§åˆ†æï¼ˆæ–°å¢ï¼‰
    
    åƒæ•¸:
        data: 3D è»Œè·¡æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: æ–¹å‘é€£çºŒæ€§åˆ†æçµæœ
    """
    joint_name = "right_wrist"
    
    positions = []
    for frame in data:
        pos = get_keypoint_safely(frame, joint_name)
        if pos is not None:
            positions.append(pos)
        else:
            positions.append(None)
    
    # è¨ˆç®—æ–¹å‘å‘é‡
    direction_vectors = []
    for i in range(1, len(positions)):
        if positions[i] is not None and positions[i - 1] is not None:
            vec = positions[i] - positions[i - 1]
            direction_vectors.append(vec)
        else:
            direction_vectors.append(None)
    
    # æª¢æ¸¬æ–¹å‘åè½‰ï¼ˆ180Â° è½‰å‘ï¼‰
    reversal_count = 0
    angle_changes = []
    
    for i in range(1, len(direction_vectors)):
        if direction_vectors[i] is not None and direction_vectors[i - 1] is not None:
            v1 = direction_vectors[i - 1]
            v2 = direction_vectors[i]
            
            n1, n2 = norm(v1), norm(v2)
            if n1 > config.epsilon and n2 > config.epsilon:
                cos_theta = np.dot(v1, v2) / (n1 * n2)
                cos_theta = np.clip(cos_theta, -1.0, 1.0)
                angle_deg = float(np.degrees(np.arccos(cos_theta)))
                angle_changes.append(angle_deg)
                
                # æª¢æ¸¬æ¥è¿‘ 180Â° çš„åè½‰
                if angle_deg > config.direction_reversal_threshold:
                    reversal_count += 1
    
    if not angle_changes:
        return {}
    
    arr = np.array(angle_changes, dtype=float)
    
    return {
        "joint": joint_name,
        "reversal_count": reversal_count,
        "reversal_rate": float(reversal_count / len(arr) * 100),
        "mean_angle_change_deg": float(np.mean(arr)),
        "median_angle_change_deg": float(np.median(arr)),
        "sample_count": len(arr)
    }


def analyze_detailed_anomalies(
    acceleration_data: dict,
    direction_change_data: dict,
    jump_anomalies_data: dict,
    direction_continuity_data: dict,
    config: ValidationConfig
) -> dict:
    """
    è©³ç´°åˆ†ææ™‚é–“å¹³æ»‘åº¦ç•°å¸¸
    
    åƒæ•¸:
        acceleration_data: åŠ é€Ÿåº¦ç•°å¸¸æ•¸æ“š
        direction_change_data: æ–¹å‘è®ŠåŒ–æ•¸æ“š
        jump_anomalies_data: è·³èºç•°å¸¸æ•¸æ“š
        direction_continuity_data: æ–¹å‘é€£çºŒæ€§æ•¸æ“š
        config: é©—è­‰é…ç½®
    
    è¿”å›:
        dict: è©³ç´°ç•°å¸¸åˆ†æçµæœ
    """
    # åŠ é€Ÿåº¦ç•°å¸¸åˆ†æ
    accel_outliers = acceleration_data.get('outlier_details', [])
    
    # è¨ˆç®—å‹•æ…‹é–¾å€¼ï¼ˆä½¿ç”¨å¹³å‡å€¼ï¼‰
    if accel_outliers:
        accel_values = [x['acceleration'] for x in accel_outliers]
        accel_mean = np.mean(accel_values)
        accel_threshold = accel_mean
    else:
        accel_threshold = 1000.0  # é»˜èªå€¼
    
    # åˆ†ç´š: åš´é‡ (>5xå¹³å‡), ä¸­ç­‰ (3-5x), è¼•å¾® (<3x)
    accel_severe = [x for x in accel_outliers if x['acceleration'] > accel_threshold * 5]
    accel_moderate = [x for x in accel_outliers if accel_threshold * 3 < x['acceleration'] <= accel_threshold * 5]
    accel_mild = [x for x in accel_outliers if x['acceleration'] <= accel_threshold * 3]
    
    # æ–¹å‘è®ŠåŒ–ç•°å¸¸
    dir_changes = direction_change_data.get('sudden_changes', [])
    
    # åˆ†ç´š: åš´é‡ (>120Â°), ä¸­ç­‰ (90-120Â°), è¼•å¾® (<90Â°)
    dir_severe = [x for x in dir_changes if x['angle_change'] > 120]
    dir_moderate = [x for x in dir_changes if 90 < x['angle_change'] <= 120]
    dir_mild = [x for x in dir_changes if x['angle_change'] <= 90]
    
    # è·³èºç•°å¸¸
    jumps = jump_anomalies_data.get('large_jumps', [])
    
    # è¨ˆç®—å‹•æ…‹é–¾å€¼ï¼ˆä½¿ç”¨å¹³å‡å€¼ï¼‰
    if jumps:
        jump_values = [x['displacement'] for x in jumps]
        jump_threshold = np.mean(jump_values)
    else:
        jump_threshold = 100.0  # é»˜èªå€¼
    
    # åˆ†ç´š: åš´é‡ (>3xå¹³å‡), ä¸­ç­‰ (2-3x), è¼•å¾® (1-2x)
    jump_severe = [x for x in jumps if x['displacement'] > jump_threshold * 3]
    jump_moderate = [x for x in jumps if jump_threshold * 2 < x['displacement'] <= jump_threshold * 3]
    jump_mild = [x for x in jumps if jump_threshold < x['displacement'] <= jump_threshold * 2]
    
    # æ–¹å‘åè½‰ï¼ˆéƒ½ç®—åš´é‡ï¼‰
    reversals = direction_continuity_data.get('reversal_count', 0)
    
    # é€£çºŒç•°å¸¸å€æ®µæª¢æ¸¬ï¼ˆåŠ é€Ÿåº¦ï¼‰
    continuous_segments = []
    if accel_outliers:
        accel_sorted = sorted(accel_outliers, key=lambda x: x['frame'])
        current_segment = None
        
        for item in accel_sorted:
            if current_segment is None:
                current_segment = {
                    "start_frame": item['frame'],
                    "end_frame": item['frame'],
                    "accelerations": [item['acceleration']]
                }
            elif item['frame'] - current_segment['end_frame'] <= 2:
                current_segment['end_frame'] = item['frame']
                current_segment['accelerations'].append(item['acceleration'])
            else:
                if len(current_segment['accelerations']) >= 3:
                    current_segment['duration'] = current_segment['end_frame'] - current_segment['start_frame'] + 1
                    current_segment['mean_acceleration'] = float(np.mean(current_segment['accelerations']))
                    current_segment['max_acceleration'] = float(np.max(current_segment['accelerations']))
                    continuous_segments.append(current_segment)
                current_segment = {
                    "start_frame": item['frame'],
                    "end_frame": item['frame'],
                    "accelerations": [item['acceleration']]
                }
        
        if current_segment and len(current_segment['accelerations']) >= 3:
            current_segment['duration'] = current_segment['end_frame'] - current_segment['start_frame'] + 1
            current_segment['mean_acceleration'] = float(np.mean(current_segment['accelerations']))
            current_segment['max_acceleration'] = float(np.max(current_segment['accelerations']))
            continuous_segments.append(current_segment)
        
        for seg in continuous_segments:
            del seg['accelerations']
    
    return {
        "total_anomaly_count": len(accel_outliers) + len(dir_changes) + len(jumps) + reversals,
        "acceleration_anomalies": {
            "total": len(accel_outliers),
            "severe": accel_severe,
            "moderate": accel_moderate,
            "mild": accel_mild,
            "threshold_used": float(accel_threshold) if accel_outliers else 0.0
        },
        "direction_change_anomalies": {
            "total": len(dir_changes),
            "severe": dir_severe,
            "moderate": dir_moderate,
            "mild": dir_mild
        },
        "jump_anomalies": {
            "total": len(jumps),
            "severe": jump_severe,
            "moderate": jump_moderate,
            "mild": jump_mild,
            "threshold_used": float(jump_threshold) if jumps else 0.0
        },
        "direction_reversals": {
            "count": reversals
        },
        "continuous_segments": sorted(continuous_segments, key=lambda x: x['duration'], reverse=True)
    }


def print_analysis_report_enhanced(
    velocity: dict,
    acceleration: dict,
    direction_change: dict,
    jump_anomalies: dict,
    smoothness: dict,
    frequency: dict,
    direction_continuity: dict,
    detailed_anomalies: dict,
    config: ValidationConfig
) -> None:
    """åˆ—å°åˆ†æå ±å‘Šï¼ˆå¢å¼·ç‰ˆï¼‰"""
    
    if velocity:
        print("\n" + "=" * 100)
        print("ã€1. é€Ÿåº¦è®ŠåŒ–ç‡ã€‘")
        print("=" * 100)
        for joint, stats in velocity.items():
            print(f"{joint}: å¹³å‡é€Ÿåº¦ {stats['mean_velocity_mm_s']:.2f} mm/s, CV={stats['cv_percent']:.2f}%")
    
    if acceleration:
        print("\n" + "=" * 100)
        print("ã€2. åŠ é€Ÿåº¦ç•°å¸¸ã€‘")
        print("=" * 100)
        print(f"ç•°å¸¸é»: {acceleration['outlier_count']} / {acceleration['sample_count']}")
        print(f"ç•°å¸¸ç‡: {acceleration['outlier_rate']:.2f}%")
    
    if direction_change:
        print("\n" + "=" * 100)
        print("ã€3. æ–¹å‘çªè®Šã€‘")
        print("=" * 100)
        print(f"çªè®Šæ¬¡æ•¸: {direction_change['sudden_change_count']}")
        print(f"å¹³å‡è§’åº¦è®ŠåŒ–: {direction_change['mean_angle_change_deg']:.2f}Â°")
    
    if jump_anomalies:
        print("\n" + "=" * 100)
        print("ã€4. ç•°å¸¸è·³èºã€‘")
        print("=" * 100)
        print(f"å¤§è·³èºæ¬¡æ•¸: {jump_anomalies['large_jump_count']}")
        print(f"æœ€å¤§ä½ç§»: {jump_anomalies['max_displacement_mm']:.2f} mm")
    
    if smoothness:
        print("\n" + "=" * 100)
        print("ã€5. å¹³æ»‘åº¦ã€‘")
        print("=" * 100)
        print(f"äºŒéšå·®åˆ†å‡å€¼: {smoothness['mean_second_diff_mm']:.2f} mm")
    
    if frequency:
        print("\n" + "=" * 100)
        print("ã€6. é »åŸŸåˆ†æ (NEW)ã€‘")
        print("=" * 100)
        print(f"X è»¸ä¸»é »: {frequency['x_axis']['dominant_frequency_hz']:.2f} Hz")
        print(f"Y è»¸ä¸»é »: {frequency['y_axis']['dominant_frequency_hz']:.2f} Hz")
        print(f"Z è»¸ä¸»é »: {frequency['z_axis']['dominant_frequency_hz']:.2f} Hz")
        print(f"é«˜é »èƒ½é‡ä½”æ¯” (X): {frequency['x_axis']['high_frequency_ratio']*100:.2f}%")
    
    if direction_continuity:
        print("\n" + "=" * 100)
        print("ã€7. æ–¹å‘é€£çºŒæ€§å¢å¼·æª¢æ¸¬ (NEW)ã€‘")
        print("=" * 100)
        print(f"æ–¹å‘åè½‰æ¬¡æ•¸: {direction_continuity['reversal_count']}")
        print(f"åè½‰ç‡: {direction_continuity['reversal_rate']:.2f}%")
    
    # è©³ç´°ç•°å¸¸åˆ†æ
    if detailed_anomalies and detailed_anomalies.get('total_anomaly_count', 0) > 0:
        print("\n" + "=" * 100)
        print("ã€8. ç•°å¸¸è©³ç´°åˆ†æã€‘")
        print("=" * 100)
        
        total = detailed_anomalies['total_anomaly_count']
        accel = detailed_anomalies['acceleration_anomalies']
        dir_chg = detailed_anomalies['direction_change_anomalies']
        jumps = detailed_anomalies['jump_anomalies']
        reversals = detailed_anomalies['direction_reversals']
        
        print(f"ç¸½ç•°å¸¸æ•¸: {total} å€‹")
        print(f"  â€¢ åŠ é€Ÿåº¦ç•°å¸¸: {accel['total']} å€‹")
        print(f"  â€¢ æ–¹å‘è®ŠåŒ–: {dir_chg['total']} å€‹")
        print(f"  â€¢ ç•°å¸¸è·³èº: {jumps['total']} å€‹")
        print(f"  â€¢ æ–¹å‘åè½‰: {reversals['count']} æ¬¡")
        print()
        
        # åŠ é€Ÿåº¦ç•°å¸¸åˆ†æ
        if accel['total'] > 0:
            print("â–¸ åŠ é€Ÿåº¦ç•°å¸¸åˆ†ç´š:")
            accel_threshold = accel.get('threshold_used', 1000.0)
            print(f"  â€¢ åš´é‡ (>{accel_threshold*5:.0f} mm/sÂ²): {len(accel['severe']):3d} å€‹ ({len(accel['severe'])/accel['total']*100:5.1f}%)")
            print(f"  â€¢ ä¸­ç­‰ ({accel_threshold*3:.0f}-{accel_threshold*5:.0f} mm/sÂ²): {len(accel['moderate']):3d} å€‹ ({len(accel['moderate'])/accel['total']*100:5.1f}%)")
            print(f"  â€¢ è¼•å¾® (<{accel_threshold*3:.0f} mm/sÂ²): {len(accel['mild']):3d} å€‹ ({len(accel['mild'])/accel['total']*100:5.1f}%)")
            print()
            
            # åš´é‡åŠ é€Ÿåº¦ç•°å¸¸ - å…¨éƒ¨é¡¯ç¤º
            if accel['severe']:
                print("â”€" * 100)
                print(f"[!] åš´é‡åŠ é€Ÿåº¦ç•°å¸¸ (>{accel_threshold*5:.0f} mm/s^2) - å…¨éƒ¨ {len(accel['severe'])} å€‹:")
                print("â”€" * 100)
                for idx, item in enumerate(accel['severe'], 1):
                    print(f" {idx:3d}. Frame {item['frame']:3d}: åŠ é€Ÿåº¦ = {item['acceleration']:8.1f} mm/sÂ²")
                print()
            
            # ä¸­ç­‰åŠ é€Ÿåº¦ç•°å¸¸ - é¡¯ç¤ºå‰ 10 å€‹
            if accel['moderate']:
                print("â”€" * 100)
                display_count = min(10, len(accel['moderate']))
                print(f"ğŸ“Š ä¸­ç­‰åŠ é€Ÿåº¦ç•°å¸¸ ({accel_threshold*3:.0f}-{accel_threshold*5:.0f} mm/sÂ²) - é¡¯ç¤ºå‰ {display_count} å€‹ï¼Œå…± {len(accel['moderate'])} å€‹:")
                print("â”€" * 100)
                moderate_sorted = sorted(accel['moderate'], key=lambda x: x['acceleration'], reverse=True)
                for idx, item in enumerate(moderate_sorted[:display_count], 1):
                    print(f" {idx:3d}. Frame {item['frame']:3d}: åŠ é€Ÿåº¦ = {item['acceleration']:8.1f} mm/sÂ²")
                if len(accel['moderate']) > display_count:
                    print(f"\n â‹® å…¶é¤˜ {len(accel['moderate']) - display_count} å€‹ä¸­ç­‰ç•°å¸¸è«‹åƒé–± JSON è¼¸å‡º")
                print()
            
            # è¼•å¾®åŠ é€Ÿåº¦ç•°å¸¸ - çµ±è¨ˆ
            if accel['mild']:
                print("â”€" * 100)
                print(f"ğŸ“‹ è¼•å¾®åŠ é€Ÿåº¦ç•°å¸¸ (<{accel_threshold*3:.0f} mm/sÂ²) - å…± {len(accel['mild'])} å€‹ï¼Œè©³è¦‹ JSON")
                print("â”€" * 100)
                print()
        
        # æ–¹å‘è®ŠåŒ–ç•°å¸¸åˆ†æ
        if dir_chg['total'] > 0:
            print("â–¸ æ–¹å‘è®ŠåŒ–ç•°å¸¸åˆ†ç´š:")
            print(f"  â€¢ åš´é‡ (>120Â°):  {len(dir_chg['severe']):3d} å€‹ ({len(dir_chg['severe'])/dir_chg['total']*100:5.1f}%)")
            print(f"  â€¢ ä¸­ç­‰ (90-120Â°): {len(dir_chg['moderate']):3d} å€‹ ({len(dir_chg['moderate'])/dir_chg['total']*100:5.1f}%)")
            print(f"  â€¢ è¼•å¾® (<90Â°):    {len(dir_chg['mild']):3d} å€‹ ({len(dir_chg['mild'])/dir_chg['total']*100:5.1f}%)")
            print()
            
            # åš´é‡æ–¹å‘è®ŠåŒ– - å…¨éƒ¨é¡¯ç¤º
            if dir_chg['severe']:
                print("â”€" * 100)
                print(f"[!] åš´é‡æ–¹å‘è®ŠåŒ– (>120Â°) - å…¨éƒ¨ {len(dir_chg['severe'])} å€‹:")
                print("â”€" * 100)
                for idx, item in enumerate(dir_chg['severe'], 1):
                    print(f" {idx:3d}. Frame {item['frame']:3d}: è§’åº¦è®ŠåŒ– = {item['angle_change']:6.1f}Â°")
                print()
            
            # ä¸­ç­‰æ–¹å‘è®ŠåŒ– - é¡¯ç¤ºå‰ 10 å€‹
            if dir_chg['moderate']:
                print("â”€" * 100)
                display_count = min(10, len(dir_chg['moderate']))
                print(f"ğŸ“Š ä¸­ç­‰æ–¹å‘è®ŠåŒ– (90-120Â°) - é¡¯ç¤ºå‰ {display_count} å€‹ï¼Œå…± {len(dir_chg['moderate'])} å€‹:")
                print("â”€" * 100)
                moderate_sorted = sorted(dir_chg['moderate'], key=lambda x: x['angle_change'], reverse=True)
                for idx, item in enumerate(moderate_sorted[:display_count], 1):
                    print(f" {idx:3d}. Frame {item['frame']:3d}: è§’åº¦è®ŠåŒ– = {item['angle_change']:6.1f}Â°")
                if len(dir_chg['moderate']) > display_count:
                    print(f"\n â‹® å…¶é¤˜ {len(dir_chg['moderate']) - display_count} å€‹ä¸­ç­‰ç•°å¸¸è«‹åƒé–± JSON è¼¸å‡º")
                print()
        
        # è·³èºç•°å¸¸åˆ†æ
        if jumps['total'] > 0:
            print("â–¸ ç•°å¸¸è·³èºåˆ†ç´š:")
            jump_threshold = jumps.get('threshold_used', 100.0)
            print(f"  â€¢ åš´é‡ (>{jump_threshold*3:.0f} mm):  {len(jumps['severe']):3d} å€‹ ({len(jumps['severe'])/jumps['total']*100:5.1f}%)")
            print(f"  â€¢ ä¸­ç­‰ ({jump_threshold*2:.0f}-{jump_threshold*3:.0f} mm): {len(jumps['moderate']):3d} å€‹ ({len(jumps['moderate'])/jumps['total']*100:5.1f}%)")
            print(f"  â€¢ è¼•å¾® ({jump_threshold:.0f}-{jump_threshold*2:.0f} mm): {len(jumps['mild']):3d} å€‹ ({len(jumps['mild'])/jumps['total']*100:5.1f}%)")
            print()
            
            # åš´é‡è·³èº - å…¨éƒ¨é¡¯ç¤º
            if jumps['severe']:
                print("â”€" * 100)
                print(f"[!] åš´é‡ç•°å¸¸è·³èº (>{jump_threshold*3:.0f} mm) - å…¨éƒ¨ {len(jumps['severe'])} å€‹:")
                print("â”€" * 100)
                for idx, item in enumerate(jumps['severe'], 1):
                    print(f" {idx:3d}. Frame {item['frame']:3d}: ä½ç§» = {item['displacement']:7.1f} mm")
                print()
        
        # é€£çºŒç•°å¸¸å€æ®µ
        segments = detailed_anomalies.get('continuous_segments', [])
        if segments:
            print("â–¸ é€£çºŒç•°å¸¸å€æ®µï¼ˆåŠ é€Ÿåº¦ï¼Œâ‰¥3 å¹€ï¼‰:")
            for seg in segments[:5]:
                print(f"  â€¢ Frame {seg['start_frame']:3d}-{seg['end_frame']:3d} ({seg['duration']:2d} å¹€): "
                      f"å¹³å‡ {seg['mean_acceleration']:7.1f} mm/sÂ², æœ€å¤§ {seg['max_acceleration']:7.1f} mm/sÂ²")
            print()
        
        print("ğŸ’¾ å®Œæ•´ç•°å¸¸åˆ—è¡¨å·²å„²å­˜è‡³ JSON:")
        print("   [V] detailed_anomalies.acceleration_anomalies - æ‰€æœ‰åŠ é€Ÿåº¦ç•°å¸¸")
        print("   [V] detailed_anomalies.direction_change_anomalies - æ‰€æœ‰æ–¹å‘è®ŠåŒ–")
        print("   [V] detailed_anomalies.jump_anomalies - æ‰€æœ‰ç•°å¸¸è·³èº")
        print("   [V] detailed_anomalies.continuous_segments - é€£çºŒç•°å¸¸å€æ®µ")


def validate_time_smoothness_analysis(
    json_3d_path: str,
    output_json_path: str = None,
    config_path: str = None
) -> dict:
    """
    æ™‚é–“å¹³æ»‘åº¦é©—è­‰åˆ†æï¼ˆä¸»å‡½æ•¸ï¼‰
    
    åƒæ•¸:
        json_3d_path: 3D è»Œè·¡ JSON æª”æ¡ˆè·¯å¾‘
        output_json_path: è¼¸å‡ºçµæœ JSON è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        config_path: é…ç½®æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
    
    è¿”å›:
        dict: å®Œæ•´åˆ†æçµæœ
    """
    # è¼‰å…¥é…ç½®
    config = load_config(config_path)
    
    # è¼‰å…¥æ•¸æ“š
    print(f"\nè¼‰å…¥æ•¸æ“š: {json_3d_path}")
    data = load_json_file(json_3d_path)
    print(f"ç¸½å¹€æ•¸: {len(data)}")
    
    # åŸ·è¡Œå„é …åˆ†æ
    print("\nåŸ·è¡Œé€Ÿåº¦åˆ†æ...")
    velocity = analyze_velocity_changes(data, config)
    
    print("åŸ·è¡ŒåŠ é€Ÿåº¦åˆ†æ...")
    acceleration = analyze_acceleration_anomalies(data, config)
    
    print("åŸ·è¡Œæ–¹å‘çªè®Šåˆ†æ...")
    direction_change = analyze_direction_changes(data, config)
    
    print("åŸ·è¡Œè·³èºç•°å¸¸åˆ†æ...")
    jump_anomalies = analyze_jump_anomalies(data, config)
    
    print("åŸ·è¡Œå¹³æ»‘åº¦åˆ†æ...")
    smoothness = analyze_smoothness(data, config)
    
    print("åŸ·è¡Œé »åŸŸåˆ†æ...")
    frequency = analyze_frequency_domain(data, config)
    
    print("åŸ·è¡Œæ–¹å‘é€£çºŒæ€§å¢å¼·æª¢æ¸¬...")
    direction_continuity = analyze_direction_continuity_enhanced(data, config)
    
    print("åŸ·è¡Œè©³ç´°ç•°å¸¸åˆ†æ...")
    detailed_anomalies = analyze_detailed_anomalies(
        acceleration, direction_change, jump_anomalies, direction_continuity, config
    )
    
    # åˆ—å°å ±å‘Š
    print_analysis_report_enhanced(
        velocity, acceleration, direction_change,
        jump_anomalies, smoothness, frequency, direction_continuity,
        detailed_anomalies, config
    )
    
    # æ•´åˆçµæœ
    results = {
        "metadata": {
            "analysis_time": datetime.now().isoformat(),
            "source_file": str(json_3d_path),
            "total_frames": int(len(data)),
            "analysis_type": "Time Smoothness Analysis"
        },
        "overall_summary": {
            "total_acceleration_outliers": acceleration.get('outlier_count', 0) if acceleration else 0,
            "total_large_jumps": jump_anomalies.get('large_jump_count', 0) if jump_anomalies else 0,
            "total_direction_reversals": direction_continuity.get('reversal_count', 0) if direction_continuity else 0
        },
        "velocity_analysis": velocity,
        "acceleration_anomalies": acceleration,
        "direction_changes": direction_change,
        "jump_anomalies": jump_anomalies,
        "smoothness_analysis": smoothness,
        "frequency_domain_analysis": frequency,
        "direction_continuity_enhanced": direction_continuity,
        "detailed_anomalies": {
            "summary": {
                "total_anomaly_count": detailed_anomalies.get('total_anomaly_count', 0),
                "acceleration_count": detailed_anomalies.get('acceleration_anomalies', {}).get('total', 0),
                "direction_change_count": detailed_anomalies.get('direction_change_anomalies', {}).get('total', 0),
                "jump_count": detailed_anomalies.get('jump_anomalies', {}).get('total', 0),
                "reversal_count": detailed_anomalies.get('direction_reversals', {}).get('count', 0)
            },
            "acceleration_anomalies": {
                "severe": detailed_anomalies.get('acceleration_anomalies', {}).get('severe', []),
                "moderate": detailed_anomalies.get('acceleration_anomalies', {}).get('moderate', []),
                "mild": detailed_anomalies.get('acceleration_anomalies', {}).get('mild', [])
            },
            "direction_change_anomalies": {
                "severe": detailed_anomalies.get('direction_change_anomalies', {}).get('severe', []),
                "moderate": detailed_anomalies.get('direction_change_anomalies', {}).get('moderate', []),
                "mild": detailed_anomalies.get('direction_change_anomalies', {}).get('mild', [])
            },
            "jump_anomalies": {
                "severe": detailed_anomalies.get('jump_anomalies', {}).get('severe', []),
                "moderate": detailed_anomalies.get('jump_anomalies', {}).get('moderate', []),
                "mild": detailed_anomalies.get('jump_anomalies', {}).get('mild', [])
            },
            "continuous_segments": detailed_anomalies.get('continuous_segments', [])
        } if detailed_anomalies.get('total_anomaly_count', 0) > 0 else {}
    }
    
    # ä¿å­˜çµæœ
    if output_json_path is None:
        output_json_path = generate_output_path(json_3d_path, '_step6_time_smoothness_results')
    
    save_json_results(results, output_json_path)
    print(f"\n[OK] çµæœå·²å„²å­˜è‡³: {output_json_path}")
    
    return results


# ========================================================
# ä¸»ç¨‹å¼
# ========================================================

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        json_3d_path = sys.argv[1]
        config_path = None
        output_json_path = None
        
        for i, arg in enumerate(sys.argv):
            if arg == '--config' and i + 1 < len(sys.argv):
                config_path = sys.argv[i + 1]
            if arg == '--output' and i + 1 < len(sys.argv):
                output_json_path = sys.argv[i + 1]
    else:
        json_3d_path = "0306_3__trajectory/trajectory__2/0306_3__2(3D_trajectory_smoothed).json"
        config_path = None
        output_json_path = None
        print("æç¤º: å¯ä½¿ç”¨å‘½ä»¤åˆ—åƒæ•¸:")
        print("  python step6_time_smoothness_v2.py <json_path> [--config <config>] [--output <output>]")
    
    try:
        results = validate_time_smoothness_analysis(
            json_3d_path,
            output_json_path,
            config_path
        )
    except Exception as e:
        print(f"\n[ERROR] åˆ†æå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
